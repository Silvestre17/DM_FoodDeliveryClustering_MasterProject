{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cdec7ce0f5dffaf1",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: center; flex-wrap: wrap;\">\n",
    "    <div style=\"flex: 1; min-width: 250px; display: flex; justify-content: center;\">\n",
    "        <img src=\"https://adnova.novaims.unl.pt/media/22ui3ptm/logo.svg\" style=\"max-width: 80%; height: auto; margin-top: 50px; margin-bottom: 50px;margin-left: 3rem;\">\n",
    "    </div>\n",
    "    <div style=\"flex: 2; text-align: center; margin-top: 20px;margin-left: 8rem;\">\n",
    "        <div style=\"font-size: 28px; font-weight: bold; line-height: 1.2;\">\n",
    "            <span style='color:#6f800f'> Data Mining Project | </span>\n",
    "            <span style='color:#393B79'>ABCDEats Inc.</span>\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold; margin-top: 10px;\">\n",
    "            Fall Semester | 2024 - 2025\n",
    "        </div>\n",
    "        <div style=\"font-size: 17px; font-weight: bold;\">\n",
    "            Master in Data Science and Advanced Analytics\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px;\">\n",
    "            <div>Andr√© Silvestre, 20240502</div>\n",
    "            <div>Filipa Pereira, 20240509</div>\n",
    "            <div>Umeima Mahomed, 20240543</div>\n",
    "        </div>\n",
    "        <div style=\"margin-top: 20px; font-weight: bold;\">\n",
    "            Group 37\n",
    "        </div>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b748580141948940",
   "metadata": {},
   "source": [
    "<div style=\"background: linear-gradient(to right,#6f800f, #393B79); \n",
    "            padding: .7px; color: white; border-radius: 300px; text-align: center;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0fbc23dd806177",
   "metadata": {},
   "source": [
    "## üìö Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dab144c37194e16a",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# For data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# For plotting and EDA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "# For preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from math import ceil\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For PCA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Disable FutureWarning\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Set the style of the visualization\n",
    "pd.set_option('display.max_columns', None)                  # display all columns\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x) # display floats with 2 decimal places\n",
    "\n",
    "# for better resolution plots\n",
    "%config InlineBackend.figure_format = 'retina' # optionally, you can change 'svg' to 'retina'\n",
    "\n",
    "# Setting seaborn style\n",
    "plt.style.use('ggplot')\n",
    "sns.set_theme(style='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8559d",
   "metadata": {},
   "source": [
    "## **Review of [`Part 1`]('./DM2425_Part1_37.ipynb')**\n",
    "\n",
    "> Before continuing with **`Part 2`** - data preprocessing process, we believe it is important to highlight some of the changes and additions we made in Part 1, as they may be essential for this stage:\n",
    "\n",
    "- We updated the description of the variable `is_chain` in the metadata to align with the values it takes. **<span style=\"color:red\">querem tamb√©m mudar o nome para chain_count?</span>**\n",
    "- Removed 13 rows that were identified as duplicates.\n",
    "- The value `'-'` in `customer_region` was replaced with `'Unknown'` to represent missing data.\n",
    "- The value `'-'` in `last_promo` was considered equivalent to `'NO PROMO'`.\n",
    "\n",
    "#### **Inconsistencies:**\n",
    "- Number of cases where `vendor_count` is greater than `product_count`: 18 (0.06%).  \n",
    "- Number of cases where `is_chain` is greater than `product_count`: 75 (0.24%).  \n",
    "- Dropped 138 rows where the number of orders is zero.\n",
    "- Number of cases where `order_count` is greater than `product_count`: 18 (0.06%), corresponding to the same cases where `vendor_count > product_count`.\n",
    "\n",
    "#### **New Variables Created:**\n",
    "- `Number of Orders`: Corresponds to the sum of the variables `DOW_0` to `DOW_6`.\n",
    "- `customer_region_buckets`: Aggregated `customer_region` into buckets `2`, `4`, `8`, and `U`.\n",
    "- `customer_age_group`: Age ranges grouped into buckets: `15-28`, `29-41`, `42-54`, `55-67`, `68-80`.\n",
    "- `days_between_orders`: Calculated as the difference between `last_order` and `first_order`.\n",
    "- `days_between_orders_per_order`: Represents the quotient between `days_between_orders` and `order_count`.\n",
    "- `last_promo_bin`: Binary variable; takes the value `0` for `'NO PROMO'` and `1` otherwise.\n",
    "- `CUI_Total_Amount_Spent`: Total spending across all cuisines during the study period.\n",
    "- `CUI_Most_Spent_Cuisine`: Name of the cuisine where the customer spent the most money.\n",
    "- `CUI_Total_Food_Types`: Count of different types of cuisines ordered.\n",
    "- `CUI_Avg_Amount_Spent`: Quotient of `CUI_Total_Amount_Spent` by `order_count`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd67dd012d4d60ec",
   "metadata": {},
   "source": [
    "# <a class='anchor' id='2'></a>\n",
    "<br>\n",
    "<style>\n",
    "@import url('https://fonts.cdnfonts.com/css/avenir-next-lt-pro?styles=29974');\n",
    "</style>\n",
    "\n",
    "<div style=\"background: linear-gradient(to right, #6f800f,#393B79); \n",
    "            padding: 10px; color: white; border-radius: 300px; text-align: center;\">\n",
    "    <center><h1 style=\"margin-left: 140px;margin-top: 10px; margin-bottom: 4px; color: white;\n",
    "                       font-size: 32px; font-family: 'Avenir Next LT Pro', sans-serif;\">\n",
    "        <b>Part 2 | Data Preprocessing </b></h1></center>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5989e709c7705bb5",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "ABCDEats = pd.read_parquet('data/DM2425_ABCDEats_1stPart.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ed3097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column 'is_chain' to 'chain_count' for better understanding\n",
    "ABCDEats.rename(columns={'is_chain': 'chain_count'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ad54d8e912bc2ec",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Variables</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>customer_region</th>\n",
       "      <th>customer_age</th>\n",
       "      <th>vendor_count</th>\n",
       "      <th>product_count</th>\n",
       "      <th>chain_count</th>\n",
       "      <th>first_order</th>\n",
       "      <th>last_order</th>\n",
       "      <th>last_promo</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>CUI_American</th>\n",
       "      <th>CUI_Asian</th>\n",
       "      <th>CUI_Beverages</th>\n",
       "      <th>CUI_Cafe</th>\n",
       "      <th>CUI_Chicken Dishes</th>\n",
       "      <th>CUI_Chinese</th>\n",
       "      <th>CUI_Desserts</th>\n",
       "      <th>CUI_Healthy</th>\n",
       "      <th>CUI_Indian</th>\n",
       "      <th>CUI_Italian</th>\n",
       "      <th>CUI_Japanese</th>\n",
       "      <th>CUI_Noodle Dishes</th>\n",
       "      <th>CUI_OTHER</th>\n",
       "      <th>CUI_Street Food / Snacks</th>\n",
       "      <th>CUI_Thai</th>\n",
       "      <th>DOW_0</th>\n",
       "      <th>DOW_1</th>\n",
       "      <th>DOW_2</th>\n",
       "      <th>DOW_3</th>\n",
       "      <th>DOW_4</th>\n",
       "      <th>DOW_5</th>\n",
       "      <th>DOW_6</th>\n",
       "      <th>HR_0</th>\n",
       "      <th>HR_1</th>\n",
       "      <th>HR_2</th>\n",
       "      <th>HR_3</th>\n",
       "      <th>HR_4</th>\n",
       "      <th>HR_5</th>\n",
       "      <th>HR_6</th>\n",
       "      <th>HR_7</th>\n",
       "      <th>HR_8</th>\n",
       "      <th>HR_9</th>\n",
       "      <th>HR_10</th>\n",
       "      <th>HR_11</th>\n",
       "      <th>HR_12</th>\n",
       "      <th>HR_13</th>\n",
       "      <th>HR_14</th>\n",
       "      <th>HR_15</th>\n",
       "      <th>HR_16</th>\n",
       "      <th>HR_17</th>\n",
       "      <th>HR_18</th>\n",
       "      <th>HR_19</th>\n",
       "      <th>HR_20</th>\n",
       "      <th>HR_21</th>\n",
       "      <th>HR_22</th>\n",
       "      <th>HR_23</th>\n",
       "      <th>order_count</th>\n",
       "      <th>customer_region_buckets</th>\n",
       "      <th>customer_age_group</th>\n",
       "      <th>days_between_orders</th>\n",
       "      <th>days_between_orders_per_order</th>\n",
       "      <th>last_promo_bin</th>\n",
       "      <th>CUI_Total_Amount_Spent</th>\n",
       "      <th>CUI_Most_Spent_Cuisine</th>\n",
       "      <th>CUI_Total_Food_Types</th>\n",
       "      <th>CUI_Avg_Amount_Spent</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1b8f824d5e</td>\n",
       "      <td>2360</td>\n",
       "      <td>18.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>DELIVERY</td>\n",
       "      <td>DIGI</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>28.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>15-28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>28.88</td>\n",
       "      <td>Indian</td>\n",
       "      <td>1</td>\n",
       "      <td>14.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5d272b9dcb</td>\n",
       "      <td>8670</td>\n",
       "      <td>17.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>DISCOUNT</td>\n",
       "      <td>DIGI</td>\n",
       "      <td>12.82</td>\n",
       "      <td>6.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>15-28</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>19.21</td>\n",
       "      <td>American</td>\n",
       "      <td>2</td>\n",
       "      <td>9.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>f6d1b2ba63</td>\n",
       "      <td>4660</td>\n",
       "      <td>38.00</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>DISCOUNT</td>\n",
       "      <td>CASH</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>29-41</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>9.20</td>\n",
       "      <td>American</td>\n",
       "      <td>1</td>\n",
       "      <td>4.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>180c632ed8</td>\n",
       "      <td>4660</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>DELIVERY</td>\n",
       "      <td>DIGI</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>31.56</td>\n",
       "      <td>Indian</td>\n",
       "      <td>2</td>\n",
       "      <td>15.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4eb37a6705</td>\n",
       "      <td>4660</td>\n",
       "      <td>20.00</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>NO PROMO</td>\n",
       "      <td>DIGI</td>\n",
       "      <td>14.57</td>\n",
       "      <td>40.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>15-28</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>55.44</td>\n",
       "      <td>Asian</td>\n",
       "      <td>2</td>\n",
       "      <td>27.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Variables customer_id customer_region  customer_age  vendor_count  \\\n",
       "index                                                               \n",
       "0          1b8f824d5e            2360         18.00             2   \n",
       "1          5d272b9dcb            8670         17.00             2   \n",
       "2          f6d1b2ba63            4660         38.00             1   \n",
       "3          180c632ed8            4660           NaN             2   \n",
       "4          4eb37a6705            4660         20.00             2   \n",
       "\n",
       "Variables  product_count  chain_count  first_order  last_order last_promo  \\\n",
       "index                                                                       \n",
       "0                      5            1         0.00           1   DELIVERY   \n",
       "1                      2            2         0.00           1   DISCOUNT   \n",
       "2                      2            2         0.00           1   DISCOUNT   \n",
       "3                      3            1         0.00           2   DELIVERY   \n",
       "4                      5            0         0.00           2   NO PROMO   \n",
       "\n",
       "Variables payment_method  CUI_American  CUI_Asian  CUI_Beverages  CUI_Cafe  \\\n",
       "index                                                                        \n",
       "0                   DIGI          0.00       0.00           0.00      0.00   \n",
       "1                   DIGI         12.82       6.39           0.00      0.00   \n",
       "2                   CASH          9.20       0.00           0.00      0.00   \n",
       "3                   DIGI          0.00      13.70           0.00      0.00   \n",
       "4                   DIGI         14.57      40.87           0.00      0.00   \n",
       "\n",
       "Variables  CUI_Chicken Dishes  CUI_Chinese  CUI_Desserts  CUI_Healthy  \\\n",
       "index                                                                   \n",
       "0                        0.00         0.00          0.00         0.00   \n",
       "1                        0.00         0.00          0.00         0.00   \n",
       "2                        0.00         0.00          0.00         0.00   \n",
       "3                        0.00         0.00          0.00         0.00   \n",
       "4                        0.00         0.00          0.00         0.00   \n",
       "\n",
       "Variables  CUI_Indian  CUI_Italian  CUI_Japanese  CUI_Noodle Dishes  \\\n",
       "index                                                                 \n",
       "0               28.88         0.00          0.00               0.00   \n",
       "1                0.00         0.00          0.00               0.00   \n",
       "2                0.00         0.00          0.00               0.00   \n",
       "3               17.86         0.00          0.00               0.00   \n",
       "4                0.00         0.00          0.00               0.00   \n",
       "\n",
       "Variables  CUI_OTHER  CUI_Street Food / Snacks  CUI_Thai  DOW_0  DOW_1  DOW_2  \\\n",
       "index                                                                           \n",
       "0               0.00                      0.00      0.00      1      0      0   \n",
       "1               0.00                      0.00      0.00      1      0      0   \n",
       "2               0.00                      0.00      0.00      1      0      0   \n",
       "3               0.00                      0.00      0.00      0      1      0   \n",
       "4               0.00                      0.00      0.00      0      1      0   \n",
       "\n",
       "Variables  DOW_3  DOW_4  DOW_5  DOW_6  HR_0  HR_1  HR_2  HR_3  HR_4  HR_5  \\\n",
       "index                                                                       \n",
       "0              0      0      0      1  0.00     0     0     0     0     0   \n",
       "1              0      0      0      1  0.00     0     0     0     0     0   \n",
       "2              0      0      0      1  0.00     0     0     0     0     0   \n",
       "3              0      0      0      1  0.00     0     0     0     0     0   \n",
       "4              0      0      0      1  0.00     0     0     0     0     0   \n",
       "\n",
       "Variables  HR_6  HR_7  HR_8  HR_9  HR_10  HR_11  HR_12  HR_13  HR_14  HR_15  \\\n",
       "index                                                                         \n",
       "0             0     0     0     0      0      0      0      0      0      0   \n",
       "1             0     0     0     0      1      1      0      0      0      0   \n",
       "2             0     0     0     1      0      1      0      0      0      0   \n",
       "3             0     0     0     0      0      1      0      0      1      0   \n",
       "4             0     0     1     1      0      0      0      0      0      0   \n",
       "\n",
       "Variables  HR_16  HR_17  HR_18  HR_19  HR_20  HR_21  HR_22  HR_23  \\\n",
       "index                                                               \n",
       "0              0      0      2      0      0      0      0      0   \n",
       "1              0      0      0      0      0      0      0      0   \n",
       "2              0      0      0      0      0      0      0      0   \n",
       "3              0      0      0      0      0      0      0      0   \n",
       "4              0      0      0      0      0      0      0      0   \n",
       "\n",
       "Variables  order_count customer_region_buckets customer_age_group  \\\n",
       "index                                                               \n",
       "0                    2                       2              15-28   \n",
       "1                    2                       8              15-28   \n",
       "2                    2                       4              29-41   \n",
       "3                    2                       4               None   \n",
       "4                    2                       4              15-28   \n",
       "\n",
       "Variables  days_between_orders  days_between_orders_per_order  last_promo_bin  \\\n",
       "index                                                                           \n",
       "0                         1.00                           0.50               1   \n",
       "1                         1.00                           0.50               1   \n",
       "2                         1.00                           0.50               1   \n",
       "3                         2.00                           1.00               1   \n",
       "4                         2.00                           1.00               0   \n",
       "\n",
       "Variables  CUI_Total_Amount_Spent CUI_Most_Spent_Cuisine  \\\n",
       "index                                                      \n",
       "0                           28.88                 Indian   \n",
       "1                           19.21               American   \n",
       "2                            9.20               American   \n",
       "3                           31.56                 Indian   \n",
       "4                           55.44                  Asian   \n",
       "\n",
       "Variables  CUI_Total_Food_Types  CUI_Avg_Amount_Spent  \n",
       "index                                                  \n",
       "0                             1                 14.44  \n",
       "1                             2                  9.61  \n",
       "2                             1                  4.60  \n",
       "3                             2                 15.78  \n",
       "4                             2                 27.72  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the first 5 rows just to confirm the import was successful\n",
    "ABCDEats.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498a9ffbcf0faefd",
   "metadata": {
    "deletable": true,
    "editable": true,
    "frozen": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of\u001b[1m rows \u001b[0m: 31737\n",
      "Number of\u001b[1m columns \u001b[0m: 66\n"
     ]
    }
   ],
   "source": [
    "# Number of rows and columns\n",
    "print('Number of\\033[1m rows \\033[0m:', ABCDEats.shape[0])\n",
    "print('Number of\\033[1m columns \\033[0m:', ABCDEats.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b408c184a9e1a8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variables\n",
       "customer_id                object\n",
       "customer_region            object\n",
       "customer_age              float64\n",
       "vendor_count                int64\n",
       "product_count               int64\n",
       "                           ...   \n",
       "last_promo_bin              int64\n",
       "CUI_Total_Amount_Spent    float64\n",
       "CUI_Most_Spent_Cuisine     object\n",
       "CUI_Total_Food_Types        int64\n",
       "CUI_Avg_Amount_Spent      float64\n",
       "Length: 66, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types\n",
    "ABCDEats.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9dc2a41dd3fc1c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209c7183dc03961",
   "metadata": {},
   "source": [
    "# **üõ†Ô∏è Data Preprocessing/Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0e8aa98110476e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous and discrete colormap\n",
    "colors = [\"#3E460F\", \"#4E5813\", \"#626E18\", \"#7A891E\", \"#98AB26\", \"#BED62F\"]\n",
    "NOVAIMS_palette_colors = sns.color_palette(colors[::-1], as_cmap=True)\n",
    "\n",
    "colors = [\"#3E460F\", \"#4E5813\", \"#626E18\", \"#7A891E\", \"#98AB26\", \"#BED62F\", \"#FFFFFF\"]\n",
    "NOVAIMS_palette_colors_continuous = LinearSegmentedColormap.from_list(\"NOVAIMS_palette\", colors[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ab8fbd1284fc114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metric columns: 58, ['customer_age', 'vendor_count', 'product_count', 'chain_count', 'first_order', 'last_order', 'CUI_American', 'CUI_Asian', 'CUI_Beverages', 'CUI_Cafe', 'CUI_Chicken Dishes', 'CUI_Chinese', 'CUI_Desserts', 'CUI_Healthy', 'CUI_Indian', 'CUI_Italian', 'CUI_Japanese', 'CUI_Noodle Dishes', 'CUI_OTHER', 'CUI_Street Food / Snacks', 'CUI_Thai', 'DOW_0', 'DOW_1', 'DOW_2', 'DOW_3', 'DOW_4', 'DOW_5', 'DOW_6', 'HR_0', 'HR_1', 'HR_2', 'HR_3', 'HR_4', 'HR_5', 'HR_6', 'HR_7', 'HR_8', 'HR_9', 'HR_10', 'HR_11', 'HR_12', 'HR_13', 'HR_14', 'HR_15', 'HR_16', 'HR_17', 'HR_18', 'HR_19', 'HR_20', 'HR_21', 'HR_22', 'HR_23', 'order_count', 'days_between_orders', 'days_between_orders_per_order', 'CUI_Total_Amount_Spent', 'CUI_Total_Food_Types', 'CUI_Avg_Amount_Spent'] \n",
      "\n",
      "Non-Metric columns: 7, ['customer_region', 'last_promo', 'payment_method', 'customer_region_buckets', 'customer_age_group', 'CUI_Most_Spent_Cuisine', 'last_promo_bin']\n"
     ]
    }
   ],
   "source": [
    "# Define metric and non-metric features\n",
    "metric_cols = ABCDEats.select_dtypes(include=['int64', 'float64']).columns.drop('last_promo_bin').to_list()\n",
    "non_metric_cols = ABCDEats[:1].select_dtypes(include=['object']).columns.append(pd.Index(['last_promo_bin'])).to_list()\n",
    "\n",
    "# Convert non_metric_cols to a pandas Index to use the drop method\n",
    "non_metric_cols = pd.Index(non_metric_cols).drop('customer_id').to_list()\n",
    "\n",
    "print(f'Metric columns: {len(metric_cols)}, {metric_cols} \\n')\n",
    "print(f'Non-Metric columns: {len(non_metric_cols)}, {non_metric_cols}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71f283fc5729f1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CUI_American',\n",
       " 'CUI_Asian',\n",
       " 'CUI_Beverages',\n",
       " 'CUI_Cafe',\n",
       " 'CUI_Chicken Dishes',\n",
       " 'CUI_Chinese',\n",
       " 'CUI_Desserts',\n",
       " 'CUI_Healthy',\n",
       " 'CUI_Indian',\n",
       " 'CUI_Italian',\n",
       " 'CUI_Japanese',\n",
       " 'CUI_Noodle Dishes',\n",
       " 'CUI_OTHER',\n",
       " 'CUI_Street Food / Snacks',\n",
       " 'CUI_Thai',\n",
       " 'CUI_Total_Amount_Spent',\n",
       " 'CUI_Most_Spent_Cuisine',\n",
       " 'CUI_Total_Food_Types',\n",
       " 'CUI_Avg_Amount_Spent']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique values of the columns 'CUI_American', 'CUI_Asian', 'CUI_Chinese', 'CUI_Italian', etc.\n",
    "cuisines_cols = [col for col in ABCDEats.columns if 'CUI_' in col]\n",
    "cuisines_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a313cb9d902add83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weeekdays columns\n",
    "weekdays_cols = ABCDEats.loc[:, 'DOW_0':'DOW_6'].columns.to_list()\n",
    "\n",
    "# Hours columns\n",
    "hours_cols = ABCDEats.loc[:, 'HR_0':'HR_23'].columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8906caad38d5d4ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Sunday',\n",
       " 1: 'Monday',\n",
       " 2: 'Tuesday',\n",
       " 3: 'Wednesday',\n",
       " 4: 'Thursday',\n",
       " 5: 'Friday',\n",
       " 6: 'Saturday'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of weekdays (0 = Sunday, 6 = Saturday)\n",
    "weekdays = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "weekdays_dict = dict(enumerate(weekdays))\n",
    "weekdays_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0360e9e6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"font-size:17px\">\n",
    "\n",
    "\n",
    "> FILIPAAAAAAAAAAAAAAAAA\n",
    "\n",
    ">For each cuisine variable, we will create a new variable that represents the proportion of spending on that cuisine relative to the total amount spent on all cuisines.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75da10",
   "metadata": {},
   "source": [
    "For each row, the proportion for a given cuisine will be computed as:\n",
    "\n",
    "$$\n",
    "\\text{Proportion of Cuisine}_i = \\frac{\\text{CUI}_i}{\\sum_{j} \\text{CUI}_j}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "$$\\qquad\\qquad\\qquad\\qquad  \\bullet \\;\\; \n",
    "\\text{CUI}_i = \\text{Spending on the specific cuisine (e.g., CUI\\_American, CUI\\_Asian, etc.).}\n",
    "$$\n",
    "\n",
    "$$\\qquad\\qquad\\qquad\\qquad  \\bullet \\;\\; \n",
    "\\sum_{j} \\text{CUI}_j = \\text{Sum of all cuisine-related columns in the row.}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d655a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing CUI_Most_Spent_Cuisine, CUI_Total_Amount_Spent, CUI_Total_Food_Types, CUI_Avg_Amount_Spent\n",
    "CUI_cols = [col for col in cuisines_cols if col not in ['CUI_Most_Spent_Cuisine', 'CUI_Total_Amount_Spent', 'CUI_Total_Food_Types', 'CUI_Avg_Amount_Spent']]\n",
    "\n",
    "\n",
    "# Create proportion variables\n",
    "for col in CUI_cols:\n",
    "    proportion_col_name = f'Proportion_{col}'\n",
    "    ABCDEats[proportion_col_name] = ABCDEats[col] / ABCDEats['CUI_Total_Amount_Spent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "774c819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where the sum of proportions is not equal to 1: 3882\n",
      "Variables customer_id customer_region  customer_age  vendor_count  \\\n",
      "index                                                               \n",
      "18         d5ef759319            8670         22.00             3   \n",
      "29         ccd38a80b8            2360         35.00             2   \n",
      "30         e8e2f0ceaa            8670         19.00             2   \n",
      "41         8d985fae15            2360         25.00             3   \n",
      "53         d6cf0c552d            2360         38.00             3   \n",
      "...               ...             ...           ...           ...   \n",
      "31269      2214e39b8c            4660         24.00             2   \n",
      "31355      0ba1b869fd            4660         26.00             2   \n",
      "31483      3bee5f9c04            8670         20.00             2   \n",
      "31550      b3f9fc72e1            8670         22.00             2   \n",
      "31700      5c50256934            8670         20.00             2   \n",
      "\n",
      "Variables  product_count  chain_count  first_order  last_order last_promo  \\\n",
      "index                                                                       \n",
      "18                     4            2         0.00           5   DELIVERY   \n",
      "29                     3            2         0.00           6   DISCOUNT   \n",
      "30                     2            0         0.00           6   DELIVERY   \n",
      "41                     3            3         0.00          10   DELIVERY   \n",
      "53                     4            3         0.00          12   NO PROMO   \n",
      "...                  ...          ...          ...         ...        ...   \n",
      "31269                  2            1        84.00          87   NO PROMO   \n",
      "31355                  2            2        85.00          86   NO PROMO   \n",
      "31483                  2            1        87.00          87   NO PROMO   \n",
      "31550                  2            2        87.00          89   NO PROMO   \n",
      "31700                  2            1        89.00          89   DISCOUNT   \n",
      "\n",
      "Variables payment_method  CUI_American  CUI_Asian  CUI_Beverages  CUI_Cafe  \\\n",
      "index                                                                        \n",
      "18                  DIGI          0.00       6.07          12.38      0.00   \n",
      "29                  CARD          0.00       0.00           0.00      0.00   \n",
      "30                  DIGI          0.00      11.75           0.00      0.00   \n",
      "41                  CARD          6.61       0.00           0.00      0.00   \n",
      "53                  CARD          0.00       0.00           0.00      5.07   \n",
      "...                  ...           ...        ...            ...       ...   \n",
      "31269               CASH          4.28       0.00           0.00      0.00   \n",
      "31355               CASH          0.00       0.00           0.00      2.73   \n",
      "31483               DIGI          5.79       0.00           0.00      0.00   \n",
      "31550               CARD          0.00       0.00           0.00      0.00   \n",
      "31700               CARD          0.00       0.00           0.00      0.00   \n",
      "\n",
      "Variables  CUI_Chicken Dishes  CUI_Chinese  CUI_Desserts  CUI_Healthy  \\\n",
      "index                                                                   \n",
      "18                       0.00         0.00          0.00         0.00   \n",
      "29                       5.52         0.00          0.00         0.00   \n",
      "30                       0.00         0.00          0.00         0.00   \n",
      "41                       0.00         0.00          0.00         2.86   \n",
      "53                       0.00         0.00          5.82         0.00   \n",
      "...                       ...          ...           ...          ...   \n",
      "31269                    0.00         0.00          0.00         0.00   \n",
      "31355                    0.00         0.00          0.00         0.00   \n",
      "31483                    0.00         0.00          0.00         0.00   \n",
      "31550                    0.00         0.00         12.25         0.00   \n",
      "31700                    0.00         0.00          6.82         0.00   \n",
      "\n",
      "Variables  CUI_Indian  CUI_Italian  CUI_Japanese  CUI_Noodle Dishes  \\\n",
      "index                                                                 \n",
      "18               0.00         0.00          0.00               0.00   \n",
      "29               0.00         0.00          0.00               0.00   \n",
      "30               0.00         0.00          0.00               0.00   \n",
      "41               0.00         0.00          0.00               0.00   \n",
      "53               0.00         0.00          0.00               0.00   \n",
      "...               ...          ...           ...                ...   \n",
      "31269            0.00         0.00          5.41               0.00   \n",
      "31355            0.00         0.00          0.00               0.00   \n",
      "31483            0.00         0.00         12.38               0.00   \n",
      "31550            0.00         0.00          0.00               0.00   \n",
      "31700            0.00         0.00          0.00               0.00   \n",
      "\n",
      "Variables  CUI_OTHER  CUI_Street Food / Snacks  CUI_Thai  DOW_0  DOW_1  DOW_2  \\\n",
      "index                                                                           \n",
      "18              0.00                     19.23      0.00      0      0      0   \n",
      "29              5.96                      0.00      0.00      0      0      0   \n",
      "30              0.00                     12.92      0.00      0      0      0   \n",
      "41              0.00                      0.00      0.00      0      0      1   \n",
      "53              8.24                      0.00      0.00      0      0      0   \n",
      "...              ...                       ...       ...    ...    ...    ...   \n",
      "31269           0.00                      0.00      0.00      0      0      1   \n",
      "31355           5.84                      0.00      0.00      1      1      0   \n",
      "31483           0.00                      0.00      0.00      0      0      2   \n",
      "31550           0.00                     11.81      0.00      0      0      1   \n",
      "31700           0.00                     12.08      0.00      0      0      0   \n",
      "\n",
      "Variables  DOW_3  DOW_4  DOW_5  DOW_6  HR_0  HR_1  HR_2  HR_3  HR_4  HR_5  \\\n",
      "index                                                                       \n",
      "18             0      2      0      1  0.00     0     0     0     0     0   \n",
      "29             0      0      1      1  0.00     0     0     0     0     0   \n",
      "30             0      0      1      1  0.00     0     0     0     0     0   \n",
      "41             1      0      0      1  0.00     0     0     0     0     0   \n",
      "53             0      1      0      2  0.00     0     0     0     0     0   \n",
      "...          ...    ...    ...    ...   ...   ...   ...   ...   ...   ...   \n",
      "31269          0      0      0      1  0.00     0     0     0     0     0   \n",
      "31355          0      0      0      0  0.00     0     0     0     0     0   \n",
      "31483          0      0      0      0  0.00     0     0     0     0     1   \n",
      "31550          0      1      0      0  0.00     0     0     0     0     0   \n",
      "31700          0      2      0      0  0.00     0     0     0     0     0   \n",
      "\n",
      "Variables  HR_6  HR_7  HR_8  HR_9  HR_10  HR_11  HR_12  HR_13  HR_14  HR_15  \\\n",
      "index                                                                         \n",
      "18            0     0     0     0      0      1      0      1      0      0   \n",
      "29            0     0     0     0      0      1      0      0      0      0   \n",
      "30            0     0     1     0      1      0      0      0      0      0   \n",
      "41            0     0     0     0      0      0      2      1      0      0   \n",
      "53            0     0     0     0      0      0      1      0      0      0   \n",
      "...         ...   ...   ...   ...    ...    ...    ...    ...    ...    ...   \n",
      "31269         0     0     0     0      1      0      1      0      0      0   \n",
      "31355         0     0     0     0      0      0      0      0      1      0   \n",
      "31483         0     0     0     0      1      0      0      0      0      0   \n",
      "31550         0     0     0     0      0      0      1      1      0      0   \n",
      "31700         0     0     0     0      0      2      0      0      0      0   \n",
      "\n",
      "Variables  HR_16  HR_17  HR_18  HR_19  HR_20  HR_21  HR_22  HR_23  \\\n",
      "index                                                               \n",
      "18             1      0      0      0      0      0      0      0   \n",
      "29             0      0      1      0      0      0      0      0   \n",
      "30             0      0      0      0      0      0      0      0   \n",
      "41             0      0      0      0      0      0      0      0   \n",
      "53             0      1      0      0      1      0      0      0   \n",
      "...          ...    ...    ...    ...    ...    ...    ...    ...   \n",
      "31269          0      0      0      0      0      0      0      0   \n",
      "31355          0      0      0      1      0      0      0      0   \n",
      "31483          0      0      0      0      0      0      0      0   \n",
      "31550          0      0      0      0      0      0      0      0   \n",
      "31700          0      0      0      0      0      0      0      0   \n",
      "\n",
      "Variables  order_count customer_region_buckets customer_age_group  \\\n",
      "index                                                               \n",
      "18                   3                       8              15-28   \n",
      "29                   2                       2              29-41   \n",
      "30                   2                       8              15-28   \n",
      "41                   3                       2              15-28   \n",
      "53                   3                       2              29-41   \n",
      "...                ...                     ...                ...   \n",
      "31269                2                       4              15-28   \n",
      "31355                2                       4              15-28   \n",
      "31483                2                       8              15-28   \n",
      "31550                2                       8              15-28   \n",
      "31700                2                       8              15-28   \n",
      "\n",
      "Variables  days_between_orders  days_between_orders_per_order  last_promo_bin  \\\n",
      "index                                                                           \n",
      "18                        5.00                           1.67               1   \n",
      "29                        6.00                           3.00               1   \n",
      "30                        6.00                           3.00               1   \n",
      "41                       10.00                           3.33               1   \n",
      "53                       12.00                           4.00               0   \n",
      "...                        ...                            ...             ...   \n",
      "31269                     3.00                           1.50               0   \n",
      "31355                     1.00                           0.50               0   \n",
      "31483                     0.00                           0.00               0   \n",
      "31550                     2.00                           1.00               0   \n",
      "31700                     0.00                           0.00               1   \n",
      "\n",
      "Variables  CUI_Total_Amount_Spent CUI_Most_Spent_Cuisine  \\\n",
      "index                                                      \n",
      "18                          37.68   Street Food / Snacks   \n",
      "29                          11.48                  OTHER   \n",
      "30                          24.67   Street Food / Snacks   \n",
      "41                           9.47               American   \n",
      "53                          19.13                  OTHER   \n",
      "...                           ...                    ...   \n",
      "31269                        9.69               Japanese   \n",
      "31355                        8.57                  OTHER   \n",
      "31483                       18.17               Japanese   \n",
      "31550                       24.06               Desserts   \n",
      "31700                       18.90   Street Food / Snacks   \n",
      "\n",
      "Variables  CUI_Total_Food_Types  CUI_Avg_Amount_Spent  \\\n",
      "index                                                   \n",
      "18                            3                 12.56   \n",
      "29                            2                  5.74   \n",
      "30                            2                 12.34   \n",
      "41                            2                  3.16   \n",
      "53                            3                  6.38   \n",
      "...                         ...                   ...   \n",
      "31269                         2                  4.85   \n",
      "31355                         2                  4.29   \n",
      "31483                         2                  9.09   \n",
      "31550                         2                 12.03   \n",
      "31700                         2                  9.45   \n",
      "\n",
      "Variables  Proportion_CUI_American  Proportion_CUI_Asian  \\\n",
      "index                                                      \n",
      "18                            0.00                  0.16   \n",
      "29                            0.00                  0.00   \n",
      "30                            0.00                  0.48   \n",
      "41                            0.70                  0.00   \n",
      "53                            0.00                  0.00   \n",
      "...                            ...                   ...   \n",
      "31269                         0.44                  0.00   \n",
      "31355                         0.00                  0.00   \n",
      "31483                         0.32                  0.00   \n",
      "31550                         0.00                  0.00   \n",
      "31700                         0.00                  0.00   \n",
      "\n",
      "Variables  Proportion_CUI_Beverages  Proportion_CUI_Cafe  \\\n",
      "index                                                      \n",
      "18                             0.33                 0.00   \n",
      "29                             0.00                 0.00   \n",
      "30                             0.00                 0.00   \n",
      "41                             0.00                 0.00   \n",
      "53                             0.00                 0.27   \n",
      "...                             ...                  ...   \n",
      "31269                          0.00                 0.00   \n",
      "31355                          0.00                 0.32   \n",
      "31483                          0.00                 0.00   \n",
      "31550                          0.00                 0.00   \n",
      "31700                          0.00                 0.00   \n",
      "\n",
      "Variables  Proportion_CUI_Chicken Dishes  Proportion_CUI_Chinese  \\\n",
      "index                                                              \n",
      "18                                  0.00                    0.00   \n",
      "29                                  0.48                    0.00   \n",
      "30                                  0.00                    0.00   \n",
      "41                                  0.00                    0.00   \n",
      "53                                  0.00                    0.00   \n",
      "...                                  ...                     ...   \n",
      "31269                               0.00                    0.00   \n",
      "31355                               0.00                    0.00   \n",
      "31483                               0.00                    0.00   \n",
      "31550                               0.00                    0.00   \n",
      "31700                               0.00                    0.00   \n",
      "\n",
      "Variables  Proportion_CUI_Desserts  Proportion_CUI_Healthy  \\\n",
      "index                                                        \n",
      "18                            0.00                    0.00   \n",
      "29                            0.00                    0.00   \n",
      "30                            0.00                    0.00   \n",
      "41                            0.00                    0.30   \n",
      "53                            0.30                    0.00   \n",
      "...                            ...                     ...   \n",
      "31269                         0.00                    0.00   \n",
      "31355                         0.00                    0.00   \n",
      "31483                         0.00                    0.00   \n",
      "31550                         0.51                    0.00   \n",
      "31700                         0.36                    0.00   \n",
      "\n",
      "Variables  Proportion_CUI_Indian  Proportion_CUI_Italian  \\\n",
      "index                                                      \n",
      "18                          0.00                    0.00   \n",
      "29                          0.00                    0.00   \n",
      "30                          0.00                    0.00   \n",
      "41                          0.00                    0.00   \n",
      "53                          0.00                    0.00   \n",
      "...                          ...                     ...   \n",
      "31269                       0.00                    0.00   \n",
      "31355                       0.00                    0.00   \n",
      "31483                       0.00                    0.00   \n",
      "31550                       0.00                    0.00   \n",
      "31700                       0.00                    0.00   \n",
      "\n",
      "Variables  Proportion_CUI_Japanese  Proportion_CUI_Noodle Dishes  \\\n",
      "index                                                              \n",
      "18                            0.00                          0.00   \n",
      "29                            0.00                          0.00   \n",
      "30                            0.00                          0.00   \n",
      "41                            0.00                          0.00   \n",
      "53                            0.00                          0.00   \n",
      "...                            ...                           ...   \n",
      "31269                         0.56                          0.00   \n",
      "31355                         0.00                          0.00   \n",
      "31483                         0.68                          0.00   \n",
      "31550                         0.00                          0.00   \n",
      "31700                         0.00                          0.00   \n",
      "\n",
      "Variables  Proportion_CUI_OTHER  Proportion_CUI_Street Food / Snacks  \\\n",
      "index                                                                  \n",
      "18                         0.00                                 0.51   \n",
      "29                         0.52                                 0.00   \n",
      "30                         0.00                                 0.52   \n",
      "41                         0.00                                 0.00   \n",
      "53                         0.43                                 0.00   \n",
      "...                         ...                                  ...   \n",
      "31269                      0.00                                 0.00   \n",
      "31355                      0.68                                 0.00   \n",
      "31483                      0.00                                 0.00   \n",
      "31550                      0.00                                 0.49   \n",
      "31700                      0.00                                 0.64   \n",
      "\n",
      "Variables  Proportion_CUI_Thai  \n",
      "index                           \n",
      "18                        0.00  \n",
      "29                        0.00  \n",
      "30                        0.00  \n",
      "41                        0.00  \n",
      "53                        0.00  \n",
      "...                        ...  \n",
      "31269                     0.00  \n",
      "31355                     0.00  \n",
      "31483                     0.00  \n",
      "31550                     0.00  \n",
      "31700                     0.00  \n",
      "\n",
      "[3882 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "#Check that for each row the sum of proportion_... is equal to 1\n",
    "proportion_cols = [f'Proportion_{col}' for col in CUI_cols]\n",
    "check_result = ABCDEats[ABCDEats[proportion_cols].sum(axis=1) != 1]\n",
    "\n",
    "print(f\"Rows where the sum of proportions is not equal to 1: {check_result.shape[0]}\")\n",
    "print(check_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5cf92078",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows where the sum of proportions is not equal to 1: 0\n",
      "Empty DataFrame\n",
      "Columns: [customer_id, customer_region, customer_age, vendor_count, product_count, chain_count, first_order, last_order, last_promo, payment_method, CUI_American, CUI_Asian, CUI_Beverages, CUI_Cafe, CUI_Chicken Dishes, CUI_Chinese, CUI_Desserts, CUI_Healthy, CUI_Indian, CUI_Italian, CUI_Japanese, CUI_Noodle Dishes, CUI_OTHER, CUI_Street Food / Snacks, CUI_Thai, DOW_0, DOW_1, DOW_2, DOW_3, DOW_4, DOW_5, DOW_6, HR_0, HR_1, HR_2, HR_3, HR_4, HR_5, HR_6, HR_7, HR_8, HR_9, HR_10, HR_11, HR_12, HR_13, HR_14, HR_15, HR_16, HR_17, HR_18, HR_19, HR_20, HR_21, HR_22, HR_23, order_count, customer_region_buckets, customer_age_group, days_between_orders, days_between_orders_per_order, last_promo_bin, CUI_Total_Amount_Spent, CUI_Most_Spent_Cuisine, CUI_Total_Food_Types, CUI_Avg_Amount_Spent, Proportion_CUI_American, Proportion_CUI_Asian, Proportion_CUI_Beverages, Proportion_CUI_Cafe, Proportion_CUI_Chicken Dishes, Proportion_CUI_Chinese, Proportion_CUI_Desserts, Proportion_CUI_Healthy, Proportion_CUI_Indian, Proportion_CUI_Italian, Proportion_CUI_Japanese, Proportion_CUI_Noodle Dishes, Proportion_CUI_OTHER, Proportion_CUI_Street Food / Snacks, Proportion_CUI_Thai]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Remove as colunas n√£o desejadas de cuisines_cols\n",
    "CUI_cols = [col for col in cuisines_cols if col not in ['CUI_Most_Spent_Cuisine', 'CUI_Total_Amount_Spent', 'CUI_Total_Food_Types', 'CUI_Avg_Amount_Spent']]\n",
    "\n",
    "# Cria as vari√°veis de propor√ß√£o\n",
    "for col in CUI_cols:\n",
    "    proportion_col_name = f'Proportion_{col}'\n",
    "    ABCDEats[proportion_col_name] = ABCDEats[col] / ABCDEats['CUI_Total_Amount_Spent'].replace(0, np.nan)  # Substitui zeros por NaN para evitar divis√£o por zero\n",
    "\n",
    "proportion_cols = [f'Proportion_{col}' for col in CUI_cols]\n",
    "check_result = ABCDEats[ABCDEats[proportion_cols].sum(axis=1).round(4) != 1]\n",
    "\n",
    "print(f\"Rows where the sum of proportions is not equal to 1: {check_result.shape[0]}\")\n",
    "print(check_result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7463e250f05c8344",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdfe94bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'last_promo_bin' to a boolean\n",
    "ABCDEats['last_promo_bin'] = ABCDEats['last_promo_bin'].astype('bool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de17ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check inconsistencies \n",
    "#    1. Number of cases where `vendor_count` is greater than `product_count`: 18 (0.06%). \n",
    "#    2. Number of cases where `chain_count` is greater than `product_count`: 75 (0.24%).  \n",
    "#    3. Dropped 138 rows where the number of orders is zero.\n",
    "#    4. Number of cases where `order_count` is greater than `product_count`: 18 (0.06%), corresponding to the same cases where `vendor_count > product_count`.\n",
    "\n",
    "# 1. Number of cases where `vendor_count` is greater than `product_count`\n",
    "print('Number of cases where `vendor_count` is greater than `product_count`:', ABCDEats[ABCDEats['vendor_count'] > ABCDEats['product_count']].shape[0])\n",
    "\n",
    "# 2. Number of cases where `chain_count` is greater than `product_count`\n",
    "print('Number of cases where `chain_count` is greater than `product_count`:', ABCDEats[ABCDEats['chain_count'] > ABCDEats['product_count']].shape[0])\n",
    "\n",
    "# 3. Number of orders is zero\n",
    "print('Number of rows where the number of orders is zero:', ABCDEats[ABCDEats['order_count'] == 0].shape[0])\n",
    "\n",
    "# 4. Number of cases where `order_count` is greater than `product_count`\n",
    "print('Number of cases where `order_count` is greater than `product_count`:', ABCDEats[ABCDEats['order_count'] > ABCDEats['product_count']].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7ea0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if cases where `vendor_count` is greater than `product_count` is the same as `order_count` is greater than `product_count`\n",
    "print('Number of cases where `vendor_count` is greater than `product_count` and `order_count` is greater than `product_count`:', \n",
    "      ABCDEats[(ABCDEats['vendor_count'] > ABCDEats['product_count']) & (ABCDEats['order_count'] > ABCDEats['product_count'])].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2774d7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check rows that have inconsistent data\n",
    "# ABCDEats[(ABCDEats['vendor_count'] > ABCDEats['product_count']) & (ABCDEats['order_count'] > ABCDEats['product_count'])]\n",
    "\n",
    "# Drop rows where `vendor_count` is greater than `product_count` is the same as `order_count` is greater than `product_count`\n",
    "print(f'Number of rows before dropping: {len(ABCDEats)}')\n",
    "ABCDEats = ABCDEats.drop(ABCDEats[(ABCDEats['vendor_count'] > ABCDEats['product_count']) & (ABCDEats['order_count'] > ABCDEats['product_count'])].index)\n",
    "print(f'Number of rows after dropping: {len(ABCDEats)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e010bdc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e0970d",
   "metadata": {},
   "source": [
    "### üîé **Missing Values [Imputation]** <a class='anchor' id='DP_NaNs'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e57cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset (n = number of missing values & % = percentage of missing values)\n",
    "NAs_df = pd.DataFrame({'n NAs': ABCDEats.isnull().sum(), \n",
    "                       '% NAs': round(ABCDEats.isnull().mean() * 100,2)})\n",
    "NAs_df.index.name = 'Variables'\n",
    "\n",
    "# Display the variables with missing values\n",
    "NAs_df[NAs_df['n NAs'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "086edd8c",
   "metadata": {},
   "source": [
    "#### **Approach:**\n",
    "\n",
    "- **`first_order`**: We will impute **deterministically** as shown below.\n",
    "- **`days_between_orders`**: We will impute calculating the difference between the **`first_order`** and **`last_order`** after imputation of **`first_order`**.\n",
    "- **`days_between_orders_per_order`**: We will impute calculating the difference between the **`first_order`** and **`last_order`** divided by the **`total_orders`** after imputation of **`first_order`**.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **`HR_0`**: We will impute **deterministically** knowing that:\n",
    " \n",
    " \n",
    "$$ \\text{Total Orders} = \\sum_{i=0}^{6} \\text{DOW}_i = \\sum_{i=0}^{23} \\text{HR}_i = \\text{HR}_0 + \\sum_{i=1}^{23} \\text{HR}_i$$\n",
    "\n",
    "$$ \\Leftrightarrow \\text{HR}_0 = \\text{Total Orders} - \\sum_{i=1}^{23} \\text{HR}_i$$\n",
    "\n",
    "$\\qquad\\qquad\\qquad Where:$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad  \\bullet \\;\\; \\text{\\textbf{Total Orders} is the total number of orders made by the customer.}$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad  \\bullet \\;\\; \\bf{HR_i} \\; \\text{is the number of orders made by the customer at hour i.}$\n",
    "\n",
    "$\\qquad\\qquad\\qquad\\qquad  \\bullet \\;\\; \\bf{HR_0} \\; \\text{is the only column with missing values.}$\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "- **`customer_age`**: We will impute using the **KNNImputer**.\n",
    "- **`customer_age_group`**: We will impute the missing values with the **`customer_age`** after imputation respective group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8ad711f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rows with customer_age missing values\n",
    "# ABCDEats[ABCDEats['customer_age'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the rows with  days_between_orders and days_between_orders_per_order missing values \n",
    "ABCDEats[ABCDEats['days_between_orders'].isnull()].fillna(0).groupby('last_order')[['first_order', 'days_between_orders', 'days_between_orders_per_order']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c64808f",
   "metadata": {},
   "source": [
    "> All cases where **`first_order`**, **`days_between_orders`** and **`days_between_orders_per_order`** are missing, have **`last_order`** equal to **$0$**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1406cb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCDEats[ABCDEats['days_between_orders'].isnull()].groupby('order_count').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46290fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First order date -> Weekday\n",
    "# Check the rows with first_order and last_order == 0/1 \n",
    "ABCDEats[(ABCDEats['first_order'] == 0) & (ABCDEats['last_order'] == 1)]  # DOW_0 & DOW_6 -> Sunday & (Saturday -> First Weekday of the dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19acde01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last order date -> Weekday\n",
    "# Check the rows with first and last_order == 90\n",
    "ABCDEats[(ABCDEats['first_order'] == 90) & (ABCDEats['last_order'] == 90)]  # DOW_5 -> Friday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c121821b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCDEats[ABCDEats['first_order'].isnull()].groupby('DOW_6').count()[['customer_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2434ccc",
   "metadata": {},
   "source": [
    "#### **Imputation | `first_order`, `days_between_orders` & `days_between_orders_per_order`**:\n",
    "\n",
    "> Deterministic imputation of **`first_order`** <br>\n",
    "> Since the cases where **`first_order`** is missing, **`last_order`** is equal to **$0$**, and after check, the first weekday of the dataset is **`Saturday` $= DOW_5$**, we can conclude that the **`first_order`** of these cases is $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5889f570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values in the 'first_order' column with 0\n",
    "ABCDEats['first_order'] = ABCDEats['first_order'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4fd525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values in the 'days_between_orders' and 'days_between_orders_per_order' knowing 'first_order'\n",
    "ABCDEats['days_between_orders'] = ABCDEats['last_order'] - ABCDEats['first_order']\n",
    "ABCDEats['days_between_orders_per_order'] = ABCDEats['days_between_orders'] / ABCDEats['order_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cfcd31",
   "metadata": {},
   "source": [
    "#### **Imputation | `HR_0`**:\n",
    "\n",
    "> Deterministic imputation of **`HR_0`** <br>\n",
    "\n",
    "> As we can see below (and as we already noted in **Part 1**), there are discrepancies between the total sum of **`DOW_0`** to **`DOW_6`** and the total sum of **`HR_0`** to **`HR_23`**. Moreover, there is no row where the sum of **`HR_0`** to **`HR_23`** exceeds the sum of **`DOW_0`** to **`DOW_6`**. This allows us to calculate **`HR_0`** deterministically, as previously mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76335ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through these variables we can know what number of orders are placed in total by summing all the columns 'DOW_0' to 'DOW_6' or 'HR_0' to 'HR_23'\n",
    "Total_Orders_DOW = ABCDEats.loc[:, 'DOW_0':'DOW_6'].sum().sum()\n",
    "\n",
    "# To check if the sum of the columns 'HR_0' to 'HR_23' is equal to the total number of orders\n",
    "Total_Orders_HR = ABCDEats.loc[:, 'HR_0':'HR_23'].sum().sum()\n",
    "print(\"Sum of the columns 'DOW_0' to 'DOW_6':\",Total_Orders_DOW)\n",
    "print(\"Sum of the columns 'HR_0' to 'HR_23':\",Total_Orders_HR)\n",
    "\n",
    "# Difference between the sum of the columns 'HR_0' to 'HR_23' and the sum of the columns 'DOW_0' to 'DOW_6'\n",
    "print(\"The difference is:\",Total_Orders_HR - Total_Orders_DOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27681c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of cases that sum of DOW_0 to DOW_6 is less than sum of HR_0 to HR_23\n",
    "print(f\"Number of cases where sum of DOW_0 to DOW_6 is less than sum of HR_0 to HR_23: \",\n",
    "      f\"{(ABCDEats.loc[:, 'DOW_0':'DOW_6'].sum(axis=1) < ABCDEats.loc[:, 'HR_0':'HR_23'].sum(axis=1)).sum()}\",\n",
    "      f\"({(ABCDEats.loc[:, 'DOW_0':'DOW_6'].sum(axis=1) < ABCDEats.loc[:, 'HR_0':'HR_23'].sum(axis=1)).sum()/len(ABCDEats) * 100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f5847d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values in the 'HR_0' column with sum(DOW_0:DOW_6) - sum(HR_1:HR_23)\n",
    "ABCDEats['HR_0'] = ABCDEats['HR_0'].fillna(ABCDEats.loc[:, 'DOW_0':'DOW_6'].sum(axis=1) - ABCDEats.loc[:, 'HR_1':'HR_23'].sum(axis=1))\n",
    "ABCDEats['HR_0'] = ABCDEats['HR_0'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a45bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Absolute and Relative Frequency Table of the column `HR_0` after imputation\n",
    "HR_0_n_freq = ABCDEats['HR_0'].value_counts().reset_index()\n",
    "HR_0_n_freq.columns = ['HR_0', 'n']\n",
    "HR_0_n_freq['%'] = round(HR_0_n_freq['n'] / ABCDEats.shape[0] * 100, 2)\n",
    "HR_0_n_freq.set_index('HR_0', inplace=True)\n",
    "pd.DataFrame(HR_0_n_freq.sort_values(by='n', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263655fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the sum of the columns 'DOW_0':'DOW_6' is equal to the sum of the columns 'HR_0':'HR_23'\n",
    "ABCDEats.loc[:, 'DOW_0':'DOW_6'].sum().sum() == ABCDEats.loc[:, 'HR_0':'HR_23'].sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69bb5251",
   "metadata": {},
   "source": [
    "#### **Imputation | `customer_age` & `customer_age_group`**:\n",
    "\n",
    "> Imputation of **`customer_age`** using the **KNNImputer** <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999a9878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values in the 'customer_age' column with KNNImputer\n",
    "ABCDEats_neighbors = ABCDEats.copy()\n",
    "\n",
    "# Seeing rows with NaNs\n",
    "nans_index = ABCDEats.isna().any(axis=1)\n",
    "ABCDEats[nans_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8af44662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Firstly, we need to scale the data before using the KNNImputer\n",
    "scaler = StandardScaler()\n",
    "ABCDEats_neighbors[metric_cols] = scaler.fit_transform(ABCDEats_neighbors[metric_cols])\n",
    "\n",
    "# KNNImputer - only works for numerical variables. Fill NaNs on ABCDEats['customer_age'] \n",
    "imputer = KNNImputer(n_neighbors=5, weights=\"uniform\")\n",
    "ABCDEats_neighbors[metric_cols] = imputer.fit_transform(ABCDEats_neighbors[metric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5038d17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See rows with NaNs imputed\n",
    "ABCDEats_neighbors.loc[nans_index, metric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "876bbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse the scaling\n",
    "ABCDEats_neighbors[metric_cols] = scaler.inverse_transform(ABCDEats_neighbors[metric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6cff08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare the imputed values with the original values\n",
    "comparison = pd.concat([ABCDEats.loc[nans_index, metric_cols], ABCDEats_neighbors.loc[nans_index, metric_cols]], axis=1, keys=['Original', 'Imputed'])\n",
    "\n",
    "# Show the comparison between the original and imputed values sorted column names\n",
    "columns_interleaved = [col for metric in metric_cols for col in [('Original', metric), ('Imputed', metric)]]\n",
    "comparison[columns_interleaved]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e59c3944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The age of a person is an integer number and KNNImputer returns a float in certain cases\n",
    "\n",
    "# Round the 'customer_age' column\n",
    "ABCDEats_neighbors['customer_age'] = ABCDEats_neighbors['customer_age'].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6732ba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See rows with NaNs imputed\n",
    "ABCDEats_neighbors.loc[nans_index, metric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616d782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in the dataset (n = number of missing values & % = percentage of missing values)\n",
    "NAs_df_neighbors = pd.DataFrame({'n NAs': ABCDEats_neighbors.isnull().sum(),\n",
    "                                 '% NAs': round(ABCDEats_neighbors.isnull().mean() * 100,2)})\n",
    "NAs_df_neighbors.index.name = 'Variables'\n",
    "NAs_df_neighbors[NAs_df_neighbors['n NAs'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4bf117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of the column 'customer_age' with Kernel Density Estimate (KDE) and BoxPlot on top of the histogram [Before & After Imputation]\n",
    "\n",
    "# Create a plot with 2 axes (one for the histogram and one for the boxplot)\n",
    "fig, (ax_box, ax_hist) = plt.subplots(2,                                               # 2 rows\n",
    "                                      sharex=True,                                     # Share the x-axis\n",
    "                                      gridspec_kw={\"height_ratios\": (.20, .80)},       # Set the height ratios\n",
    "                                      figsize=(12, 6))                                 # Set the figure size\n",
    "\n",
    "# Plot the Boxplot on the top\n",
    "sns.boxplot(ABCDEats['customer_age'], color='#6f800f', orient='h', ax=ax_box, width=0.4, boxprops=dict(alpha=.5))\n",
    "sns.boxplot(ABCDEats_neighbors['customer_age'], color='#286dec', orient='h', ax=ax_box, width=0.4, boxprops=dict(alpha=.3))\n",
    "\n",
    "# Plot the Histogram and the KDE on the bottom\n",
    "sns.histplot(ABCDEats['customer_age'], bins=ABCDEats['customer_age'].nunique(), color='#6f800f', alpha=0.5, stat='percent', kde=True, ax=ax_hist, label='Original')\n",
    "sns.histplot(ABCDEats_neighbors['customer_age'], bins=ABCDEats_neighbors['customer_age'].nunique(), color='#286dec', alpha=0.3, stat='percent', kde=True, ax=ax_hist, label='Imputed')\n",
    "\n",
    "# Add title and labels\n",
    "ax_box.set_title('Histogram with KDE and Boxplot of Customer Age\\n', fontweight='bold', fontsize=16)\n",
    "ax_box.set(xlabel='')\n",
    "ax_hist.set_xlabel('Customer Age', fontweight='bold', fontsize=10)\n",
    "ax_hist.set_ylabel('%\\n', fontweight='bold', fontsize=10)\n",
    "\n",
    "# Add mean, median and percentiles to the plot\n",
    "mean_age = ABCDEats['customer_age'].mean()\n",
    "median_age = ABCDEats['customer_age'].median()\n",
    "q1_age = ABCDEats['customer_age'].quantile(0.25)\n",
    "q3_age = ABCDEats['customer_age'].quantile(0.75)\n",
    "\n",
    "mean_age_neighbors = ABCDEats_neighbors['customer_age'].mean()\n",
    "median_age_neighbors = ABCDEats_neighbors['customer_age'].median()\n",
    "q1_age_neighbors = ABCDEats_neighbors['customer_age'].quantile(0.25)\n",
    "q3_age_neighbors = ABCDEats_neighbors['customer_age'].quantile(0.75)\n",
    "\n",
    "plt.axvline(mean_age, color='#806F0F', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Mean (Original):}} {mean_age:.1f}$')\n",
    "plt.axvline(mean_age_neighbors, color='#B0C4DE', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Mean (Imputed):}} {mean_age_neighbors:.1f}$')\n",
    "plt.axvline(median_age, color='#2A3006', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Median (Original):}} {median_age:.1f}$')\n",
    "plt.axvline(median_age_neighbors, color='#4682B4', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Median (Imputed):}} {median_age_neighbors:.1f}$')\n",
    "plt.axvline(q1_age, color='#6F0F80', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Q1 (Original):}} {q1_age:.1f}$')\n",
    "plt.axvline(q1_age_neighbors, color='#5F9EA0', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Q1 (Imputed):}} {q1_age_neighbors:.1f}$')\n",
    "plt.axvline(q3_age, color='#800F6F', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Q3 (Original):}} {q3_age:.1f}$')\n",
    "plt.axvline(q3_age_neighbors, color='#6495ED', linestyle='--', linewidth=1.5, alpha=0.8, label=rf'$\\mathbf{{Q3 (Imputed):}} {q3_age_neighbors:.1f}$')\n",
    "\n",
    "plt.legend(fontsize=10, title='Statistics', title_fontproperties={'weight':'bold', 'size':'12'},\n",
    "           labelspacing=0.8, borderpad=0.8, frameon=False)\n",
    "\n",
    "sns.despine(top=True, right=True, ax=ax_hist)\n",
    "sns.despine(top=True, right=True, bottom=True, ax=ax_box)\n",
    "plt.tight_layout()\n",
    "fig.savefig('./EDA_Outputs/Histogram_KDE_Boxplot_Customer_Age_Comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401cd1af",
   "metadata": {},
   "source": [
    "> Comparison distribution of **`customer_age`** before and after imputation we can see that the distribution is equal!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bc9853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the 'customer_age' column of the original dataset with the 'customer_age' column of the dataset with imputed values\n",
    "ABCDEats['customer_age'] = ABCDEats_neighbors['customer_age']\n",
    "ABCDEats['customer_age'].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a859c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing values in the 'customer_age_group' column with the 'customer_age' column after imputation\n",
    "ABCDEats['customer_age_group'] = pd.cut(ABCDEats['customer_age'], bins=[14, 28, 41, 54, 67, 80], labels=['15-28', '29-41', '42-54', '55-67', '68-80'])\n",
    "\n",
    "# Check the variable 'customer_age_group' - Absolute and Relative Frequency Table\n",
    "customer_age_group_n_freq = ABCDEats['customer_age_group'].value_counts().reset_index()\n",
    "customer_age_group_n_freq.columns = ['customer_age_group', 'n']\n",
    "customer_age_group_n_freq['%'] = round(customer_age_group_n_freq['n'] / ABCDEats.shape[0] * 100, 2)\n",
    "customer_age_group_n_freq.set_index('customer_age_group', inplace=True)\n",
    "pd.DataFrame(customer_age_group_n_freq.sort_values(by='n', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1558b23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that sum of '%' column is 100\n",
    "round(customer_age_group_n_freq['%'].sum(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce2d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that ABCDEats has no missing values\n",
    "print(f'Number of missing values in ABCDEats: {ABCDEats.isnull().sum().sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f2c0f5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62fdb01",
   "metadata": {},
   "source": [
    "### üèÆ **Outliers** <a class='anchor' id='DP_Outliers'></a> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "74321466",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for outlier detection, based on IQR method\n",
    "def detect_outliers(df,features, dfoutput=False, info=True):\n",
    "    \"\"\"\n",
    "    Detect outliers in the DataFrame based on the InterQuartile Range (IQR) method.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to detect the outliers.\n",
    "        features (list): The list of features to detect the outliers.\n",
    "        dfoutput (bool, optional): Boolean to return the DataFrame with the outliers. Defaults to False.\n",
    "        info (bool, optional): Boolean to print the information about the outliers. Defaults to True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the outliers (if dfoutput=True).\n",
    "        pd.DataFrame: Information about the outliers (if info=True and dfoutput=False or info=True and dfoutput=True).\n",
    "    \"\"\"\n",
    "    # Check if features is a list\n",
    "    if not isinstance(features, list):\n",
    "        features = [features]\n",
    "    \n",
    "    if len(features) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Detect outliers in 1 features\n",
    "    for feature in features:\n",
    "        Q1 = df[feature].quantile(0.25)       # 1st quartile\n",
    "        Q3 = df[feature].quantile(0.75)       # 3rd quartile\n",
    "        IQR = Q3 - Q1                         # InterQuartile Range\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        \n",
    "        outliers = df[(df[feature] < lower_bound) | (df[feature] > upper_bound)]\n",
    "        \n",
    "        # Print the information about the outliers\n",
    "        if info:\n",
    "            # print('\\033[1m', feature, '\\033[0m',\n",
    "            #         '\\n  1st Quartile:', Q1, '  | 3rd Quartile:', Q3, '  | IQR:', IQR,\n",
    "            #         '\\n  Lower Bound:', lower_bound, '  | Upper Bound:', upper_bound,\n",
    "            #         '\\n\\n  Number of outliers:', len(outliers), '(', round(len(outliers)/len(df)*100, 2), '%)',\n",
    "            #         '\\n    Min:', outliers[feature].min(), '  | Max:', outliers[feature].max(), '\\n')\n",
    "            \n",
    "            # Save the information that are printed in a DataFrame format\n",
    "            outliers_info = pd.DataFrame({\n",
    "                'Feature': feature,\n",
    "                '1st Quartile': Q1,\n",
    "                '3rd Quartile': Q3,\n",
    "                'IQR': IQR,\n",
    "                'Lower Bound': lower_bound,\n",
    "                'Upper Bound': upper_bound,\n",
    "                'Number of Outliers': len(outliers),\n",
    "                'Percentage of Outliers (%)': round(len(outliers)/len(df)*100, 2),\n",
    "                'Min': outliers[feature].min(),\n",
    "                'Max': outliers[feature].max()\n",
    "            }, index=[0])\n",
    "            \n",
    "            # Return the DataFrame with the information about the outliers\n",
    "            return outliers_info\n",
    "            \n",
    "        # Return DataFrame with the outliers and the information about the outliers\n",
    "        if dfoutput:\n",
    "            return outliers_info, outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142f6f39cf22a8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function 'detect_outliers' to all the metric columns\n",
    "for col in metric_cols:  \n",
    "    # If it is the first column, save the information about the outliers\n",
    "    if col == metric_cols[0]:\n",
    "        outliers_info = detect_outliers(ABCDEats, col, info=True)\n",
    "    else:\n",
    "        # Combine the information about the outliers of all the columns in a single DataFrame\n",
    "        outliers_info = pd.concat([outliers_info, detect_outliers(ABCDEats, col, info=True)], ignore_index=True)\n",
    "    \n",
    "    \n",
    "outliers_info.set_index('Feature', inplace=True)\n",
    "\n",
    "# Personalize the DataFrame with a grey color for the rows without outliers\n",
    "def highlight_no_outliers(row):\n",
    "    # Check if the \"Number of Outliers\" column is zero\n",
    "    if row['Number of Outliers'] == 0:\n",
    "        return ['background-color: #ECEDDF'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "# Apply styling to the DataFrame\n",
    "outliers_info.style.format({\n",
    "    col: '{:.2f}' for col in outliers_info.select_dtypes('float64').columns\n",
    "}).apply(highlight_no_outliers, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb48f80",
   "metadata": {},
   "source": [
    "> **[NOTE:]** If we use the outlier removal method for all the variables, we will lose all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6106a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IQR\n",
    "\n",
    "# Calculate Q1, Q3, IQR\n",
    "q25 = ABCDEats[metric_cols].quantile(.25)\n",
    "q75 = ABCDEats[metric_cols].quantile(.75)\n",
    "iqr = (q75 - q25)\n",
    "\n",
    "# Compute upper and lower limit \n",
    "# lower_limit = Q1 -1.5*IQR\n",
    "lower_lim = q25 - 1.5 * iqr\n",
    "\n",
    "# upper_limit = Q3 + 1.5*IQR\n",
    "upper_lim = q75 + 1.5 * iqr\n",
    "\n",
    "filters_iqr = []\n",
    "for metric in metric_cols:\n",
    "    # Filter the data\n",
    "    filter_iqr = (ABCDEats[metric] < lower_lim[metric]) | (ABCDEats[metric] > upper_lim[metric])\n",
    "    filters_iqr.append(filter_iqr)\n",
    "    \n",
    "filters_iqr_all = np.all(filters_iqr, axis=0)\n",
    "\n",
    "df_iqr = ABCDEats[filters_iqr_all]\n",
    "print('Percentage of data kept after removing outliers:', 100*(np.round(df_iqr.shape[0] / ABCDEats.shape[0], 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e4317",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"font-size:17px\">\n",
    "    <b>üîç Outliers Detection:</b> <br>\n",
    "    <ul>\n",
    "        <li> <b>Quantile-based method:</b> We use the <b>Interquartile Range (IQR)</b> method to detect outliers. </li>\n",
    "        <li> <b>Threshold:</b> We consider as outliers the values that are below <b>Q1 - 1.5 * IQR</b> and above <b>Q3 + 1.5 * IQR</b>. </li>\n",
    "    </ul>\n",
    "\n",
    "> AAAAAAAAAAAAAAAAAAAAA\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa2df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the IQR\n",
    "\n",
    "# Calculate Q1, Q3, IQR\n",
    "q25 = ABCDEats[metric_cols].quantile(.25)\n",
    "q75 = ABCDEats[metric_cols].quantile(.75)\n",
    "iqr = (q75 - q25)\n",
    "\n",
    "# Compute upper and lower limit \n",
    "# lower_limit = Q1 -1.5*IQR\n",
    "lower_lim = q25 - 1.5 * iqr\n",
    "\n",
    "# upper_limit = Q3 + 1.5*IQR\n",
    "upper_lim = q75 + 1.5 * iqr\n",
    "\n",
    "filters_iqr = []\n",
    "for metric in set(metric_cols) - set(cuisines_cols) - set(weekdays_cols) - set(hours_cols) | \\\n",
    "    set(['CUI_Total_Amount_Spent', 'CUI_Total_Food_Types', 'CUI_Avg_Amount_Spent']): \n",
    "    llim = lower_lim[metric]\n",
    "    ulim = upper_lim[metric]\n",
    "    filters_iqr.append(ABCDEats[metric].between(llim, ulim, inclusive='neither'))\n",
    "\n",
    "filters_iqr_all = np.all(filters_iqr, axis=0)\n",
    "\n",
    "df_iqr = ABCDEats[filters_iqr_all]\n",
    "print('Percentage of data kept after removing outliers:', 100*(np.round(df_iqr.shape[0] / ABCDEats.shape[0], 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a61ec4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filters_man = (\n",
    "    (ABCDEats['customer_age'] <= 65)\n",
    "    &\n",
    "    (ABCDEats['product_count'] <= 100)\n",
    "    &\n",
    "    (ABCDEats['vendor_count'] <= 30)\n",
    "    &\n",
    "    (ABCDEats['chain_count'] <= 50)\n",
    "    &\n",
    "    (ABCDEats['order_count'] <= 60)\n",
    "    &\n",
    "    # CUI - Based on Histograms & Boxplots\n",
    "    (ABCDEats['CUI_American'] <= 100)\n",
    "    &\n",
    "    (ABCDEats['CUI_Asian'] <= 250)\n",
    "    &\n",
    "    (ABCDEats['CUI_Beverages'] <= 100)\n",
    "    &\n",
    "    (ABCDEats['CUI_Cafe'] <= 100)\n",
    "    &\n",
    "    (ABCDEats['CUI_Chicken Dishes'] <= 50)\n",
    "    &\n",
    "    (ABCDEats['CUI_Chinese'] <= 175)\n",
    "    &\n",
    "    (ABCDEats['CUI_Desserts'] <= 75)\n",
    "    &\n",
    "    (ABCDEats['CUI_Healthy'] <= 75)\n",
    "    &\n",
    "    (ABCDEats['CUI_Indian'] <= 75)\n",
    "    &\n",
    "    (ABCDEats['CUI_Italian'] <= 175)\n",
    "    &\n",
    "    (ABCDEats['CUI_Japanese'] <= 150)\n",
    "    &\n",
    "    (ABCDEats['CUI_Noodle Dishes'] <= 75)\n",
    "    &\n",
    "    (ABCDEats['CUI_OTHER'] <= 125)\n",
    "    &\n",
    "    (ABCDEats['CUI_Street Food / Snacks'] <= 175)\n",
    "    &\n",
    "    (ABCDEats['CUI_Thai'] <= 60)\n",
    "    &\n",
    "    # DOW - Based on Histograms & Boxplots\n",
    "    (ABCDEats['DOW_0'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['DOW_1'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['DOW_2'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['DOW_3'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['DOW_4'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['DOW_5'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['DOW_6'] <= 15)\n",
    "    &\n",
    "    # HR - Based on Histograms & Boxplots (10 for all, except HR_5 -> 6 | HR_8 -> 17 | HR_10 -> 15 | HR_11 -> 15 | HR_12 -> 15 | \n",
    "    #                                                         HR_17 -> 15 | HR_18 -> 15 | HR_19 -> 15 | HR_21 -> 7 | HR_23 -> 7) \n",
    "    (ABCDEats['HR_0'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_1'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_2'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_3'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_4'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_5'] <= 6)\n",
    "    &\n",
    "    (ABCDEats['HR_6'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_7'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_8'] <= 17)\n",
    "    &\n",
    "    (ABCDEats['HR_9'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_10'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['HR_11'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['HR_12'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['HR_13'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_14'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_15'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_16'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_17'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['HR_18'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['HR_19'] <= 15)\n",
    "    &\n",
    "    (ABCDEats['HR_20'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_21'] <= 7)\n",
    "    &\n",
    "    (ABCDEats['HR_22'] <= 10)\n",
    "    &\n",
    "    (ABCDEats['HR_23'] <= 7)   \n",
    ")\n",
    "\n",
    "df_man = ABCDEats[filters_man]\n",
    "print('Percentage of data kept after removing outliers:', 100*np.round(df_man.shape[0] / ABCDEats.shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b7d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining different outlier methods\n",
    "# More robust/ consistent outlier detection method:\n",
    "df_out = ABCDEats[(filters_iqr_all | filters_man)] \n",
    "print('Percentage of data kept after removing outliers:', 100*np.round(df_out.shape[0] / ABCDEats.shape[0], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a044882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots of the metric columns before and after removing the outliers\n",
    "frows = 8\n",
    "fcols = ceil(len(metric_cols)/frows)\n",
    "\n",
    "fig = plt.figure(figsize=(22,25))\n",
    "subfigs = fig.subfigures(frows, fcols, wspace=.03, hspace=.03)\n",
    "\n",
    "for sfig, feat in zip(subfigs.flatten(), metric_cols):\n",
    "    \n",
    "    # Create 2 subplots\n",
    "    axes = sfig.subplots(2, 1, sharex=True)\n",
    "    \n",
    "    # Boxplot before removing the outliers\n",
    "    sns.boxplot(x=ABCDEats[feat], ax=axes[0], color='#6f800f')\n",
    "    axes[0].set_ylabel('Original', fontweight='bold')\n",
    "    axes[0].set_title(feat, fontsize='large')\n",
    "    \n",
    "    # Boxplot after removing the outliers\n",
    "    sns.boxplot(x=df_out[feat], ax=axes[1], color='#bEd62f')\n",
    "    axes[1].set_ylabel('\\nOutliers\\nRemoved', fontweight='bold')\n",
    "    axes[1].set_xlabel('')\n",
    "\n",
    "    # Subfigure Aesthetics\n",
    "    sfig.set_facecolor(\"#F9F9F9\")\n",
    "    \n",
    "    sfig.subplots_adjust(left=.2, right=.95, bottom=.1,)\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('./Preprocessing_Outputs/Boxplots_With_Without_Outliers.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec21b60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "\n",
    "#### **Outliers Detection**  | Analysis\n",
    "\n",
    "- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "33b1c54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot ALL Numeric Variables' Histograms with Boxplots [Before & After Imputation]\n",
    "# sp_rows = 9\n",
    "# sp_cols = 6\n",
    "\n",
    "# # Prepare figure. Create individual axes where each histogram and boxplot will be placed\n",
    "# fig, axes = plt.subplots(sp_rows * 2, sp_cols,                                        # Create subplots\n",
    "#                          figsize=(20, 4*sp_rows),                                     # Set the figure size\n",
    "#                          tight_layout=True,                                           # Automatically adjust subplot parameters to give specified padding\n",
    "#                          gridspec_kw={'height_ratios': [0.2, 0.8] * sp_rows})         # Set the height ratios of the subplots\n",
    "\n",
    "# # Adjust the space between subplots\n",
    "# plt.subplots_adjust(hspace=0.5)  # Increase the vertical space between subplots\n",
    "\n",
    "# # Plot data\n",
    "# # Iterate across axes objects and associate each histogram and boxplot\n",
    "# for i, (ax_box, ax_hist, feat) in enumerate(zip(axes[::2].flatten(), axes[1::2].flatten(), metric_cols)):\n",
    "\n",
    "#     # Plot the Boxplot on the top\n",
    "#     sns.boxplot(ABCDEats[feat], color='#bEd62f', orient='h', ax=ax_box, width=0.4, boxprops=dict(alpha=.5))\n",
    "#     sns.boxplot(df_out[feat], color='#286dec', orient='h', ax=ax_box, width=0.4, boxprops=dict(alpha=.3))\n",
    "    \n",
    "#     # Plot the Histogram and the KDE on the bottom\n",
    "#     sns.histplot(ABCDEats[feat], color='#bEd62f', kde=True, stat='percent', alpha=0.6, ax=ax_hist, label='Original')\n",
    "#     sns.histplot(df_out[feat], color='#286dec', kde=True, stat='percent', alpha=0.3, ax=ax_hist, label='After Preprocess')\n",
    "    \n",
    "#     # Add mean, median and percentiles to the plot\n",
    "#     mean_val = ABCDEats[feat].mean()\n",
    "#     median_val = ABCDEats[feat].median()\n",
    "#     q1_val = ABCDEats[feat].quantile(0.25)\n",
    "#     q3_val = ABCDEats[feat].quantile(0.75)\n",
    "    \n",
    "#     mean_val_neighbors = df_out[feat].mean()\n",
    "#     median_val_neighbors = df_out[feat].median()\n",
    "#     q1_val_neighbors = df_out[feat].quantile(0.25)\n",
    "#     q3_val_neighbors = df_out[feat].quantile(0.75)\n",
    "    \n",
    "#     ax_hist.axvline(mean_val, color='#806F0F', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Mean (Original): {mean_val:.1f}')\n",
    "#     ax_hist.axvline(mean_val_neighbors, color='#B0C4DE', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Mean (After Preprocess): {mean_val_neighbors:.1f}')\n",
    "#     ax_hist.axvline(median_val, color='#2A3006', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Median (Original): {median_val:.1f}')\n",
    "#     ax_hist.axvline(median_val_neighbors, color='#4682B4', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Median (After Preprocess): {median_val_neighbors:.1f}')\n",
    "#     ax_hist.axvline(q1_val, color='#6F0F80', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Q1 (Original): {q1_val:.1f}')\n",
    "#     ax_hist.axvline(q1_val_neighbors, color='#5F9EA0', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Q1 (After Preprocess): {q1_val_neighbors:.1f}')\n",
    "#     ax_hist.axvline(q3_val, color='#800F6F', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Q3 (Original): {q3_val:.1f}')\n",
    "#     ax_hist.axvline(q3_val_neighbors, color='#6495ED', linestyle='--', linewidth=1.5, alpha=0.8, label=f'Q3 (After Preprocess): {q3_val_neighbors:.1f}')\n",
    "\n",
    "#     # Add a legend to the histogram\n",
    "#     ax_hist.legend(loc='best',          # Position of the legend (automatic placement to avoid overlapping)\n",
    "#                    title='Statistics',  # Title of the legend \n",
    "#                    title_fontproperties={'weight':'bold',  # Title font weight\n",
    "#                                          'size':'8'},     # Title font size\n",
    "#                    fontsize=6,          # Legend font size\n",
    "#                    labelspacing=0.8,    # Spacing between the legend handles and labels\n",
    "#                    borderpad=0.8,       # Border pad around the legend\n",
    "#                    frameon=False)       # Whether to draw a frame around the legend\n",
    "    \n",
    "#     # Customizing the titles and labels of the plots\n",
    "#     ax_box.set_xlabel(None)\n",
    "#     ax_box.set_ylabel(None)\n",
    "#     ax_hist.set_title(feat, y=-0.30, fontweight='bold')\n",
    "#     ax_hist.set_xlabel(None)\n",
    "#     ax_hist.set_ylabel(None)\n",
    "    \n",
    "#     # Add y-label 'Count' to the first plots on the left\n",
    "#     if i % sp_cols == 0:\n",
    "#         ax_hist.set_ylabel('Count (n)\\n', fontsize=10, fontweight='bold')\n",
    "    \n",
    "#     # Remove the top and right spines for a cleaner look\n",
    "#     sns.despine(ax=ax_box, top=True, right=True)\n",
    "#     sns.despine(ax=ax_hist, top=True, right=True)\n",
    "\n",
    "# # Remove any unused subplots (empty subplots)\n",
    "# axes.flatten()[-1].set_visible(False)\n",
    "# axes.flatten()[-2].set_visible(False)\n",
    "# axes.flatten()[-sp_cols-1].set_visible(False)\n",
    "# axes.flatten()[-sp_cols-2].set_visible(False)\n",
    "\n",
    "# # Layout\n",
    "# # Add a centered title to the figure:\n",
    "# plt.suptitle(\"Numeric Variables' Histograms with Boxplots\\n\\n\\n\", fontweight='bold', fontsize=16)\n",
    "# fig.savefig('./Preprocessing_Outputs/Numeric_Variables_Histograms_Boxplots.png', dpi=300, bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20af72f7",
   "metadata": {},
   "source": [
    "![Outliers](./Preprocessing_Outputs/Numeric_Variables_Histograms_Boxplots.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2900c40",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size: 17px\">\n",
    "\n",
    "### Analysis after **Preprocessing**:\n",
    "\n",
    "\n",
    "\n",
    "##### **Final Decision:**\n",
    "\n",
    "> AAAAAAAAAAAA\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "10acf61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using both filter methods\n",
    "ABCDEats = df_out.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function 'detect_outliers' to all the metric columns\n",
    "for col in metric_cols:  \n",
    "    # If it is the first column, save the information about the outliers\n",
    "    if col == metric_cols[0]:\n",
    "        outliers_info_after = detect_outliers(ABCDEats, col, info=True)\n",
    "    else:\n",
    "        # Combine the information about the outliers of all the columns in a single DataFrame\n",
    "        outliers_info_after = pd.concat([outliers_info_after, detect_outliers(ABCDEats, col, info=True)], ignore_index=True)\n",
    "    \n",
    "    \n",
    "outliers_info_after.set_index('Feature', inplace=True)\n",
    "\n",
    "# Personalize the DataFrame with a grey color for the rows without outliers\n",
    "def highlight_no_outliers(row):\n",
    "    # Check if the \"Number of Outliers\" column is zero\n",
    "    if row['Number of Outliers'] == 0:\n",
    "        return ['background-color: #ECEDDF'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "# Apply styling to the DataFrame\n",
    "outliers_info_after.style.format({\n",
    "    col: '{:.2f}' for col in outliers_info_after.select_dtypes('float64').columns\n",
    "}).apply(highlight_no_outliers, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e12cb8e9",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1347b2c9",
   "metadata": {},
   "source": [
    "# **üìä Redo EDA After Preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b5710",
   "metadata": {},
   "source": [
    "## **üîó Correlation Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87430b6",
   "metadata": {},
   "source": [
    "### **Numerical Variable VS Numerical Variable**\n",
    "\n",
    " > Compared to the **Pearson correlation** coefficient, the **Spearman correlation** is more robust to outliers and non-linear relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "765a5c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enconding 'customer_age_group' to a numerical variable\n",
    "code_age_group = {'15-28': 1, '29-41': 2, '42-54': 3, '55-67': 4, '68-80': 5}\n",
    "ABCDEats['customer_age_group'] = ABCDEats['customer_age_group'].map(code_age_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix of the all columns - Numerical Variables\n",
    "correlation = ABCDEats[['customer_age_group'] + metric_cols].corr(method='spearman')              # Because the data is not normally distributed\n",
    "\n",
    "# Round the values of the correlation matrix to 2 decimal places.\n",
    "correlation = correlation.round(2)\n",
    "\n",
    "# Show only high or low values: values above |0.4| will appear annotated in the plot\n",
    "mask_annot = np.absolute(correlation.values) >= 0.4\n",
    "annot = np.where(mask_annot, correlation.values, np.full(correlation.shape,\"\"))\n",
    "\n",
    "# Create a mask to hide the upper triangle of the correlation matrix\n",
    "mask = np.zeros_like(correlation, dtype=np.bool_)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Create a custom diverging palette from red (-1) to white (0) to green (1)\n",
    "# cmap = sns.diverging_palette(10, 130, s=100, l=50, n=9, center='light', as_cmap=True)\n",
    "cmap = LinearSegmentedColormap.from_list(\"correlation_cmap\", [\"#AB3826\", \"white\", \"#0F8036\"])\n",
    "\n",
    "# Plot the correlation matrix as a Heatmap\n",
    "fig = plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation, mask=mask, cmap=cmap, annot=annot, fmt='s', \n",
    "            annot_kws={'fontsize':8}, cbar_kws={'shrink':0.8},\n",
    "            vmin=-1, vmax=1, center=0, linewidths=0.5, square=True)\n",
    "plt.title('Correlation Matrix of the Numerical Variables\\n', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.xticks(fontsize=8, fontweight ='bold')\n",
    "plt.yticks(fontsize=8, fontweight ='bold')\n",
    "plt.tight_layout()\n",
    "fig.savefig('./Preprocessing_Outputs/Correlation_Matrix_Numerical_Variables.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6175a3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of features with correlation > 0.8 (Multicollinearity)\n",
    "for col in correlation.columns:\n",
    "    if correlation[col][(correlation[col] > 0.8) & (correlation[col] < 1)].any():\n",
    "        print(f\"\\nFeatures with correlation > 0.8 with {col}:\")\n",
    "        print(correlation[col][(correlation[col] > 0.8) & (correlation[col] < 1)].to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "64517ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the results of multicollinearity after drop 'vender_count' + 'product_count' + 'days_between_orders' + 'customer_age_group'\n",
    "correlation = ABCDEats[['customer_age_group'] + metric_cols].drop(columns=['vendor_count', 'product_count', 'days_between_orders', 'customer_age_group']).corr(method='spearman')              # Because ...\n",
    "\n",
    "# List of features with correlation > 0.8 (Multicollinearity)\n",
    "for col in correlation.columns:\n",
    "    if correlation[col][(correlation[col] > 0.8) & (correlation[col] < 1)].any():\n",
    "        print(f\"\\nFeatures with correlation > 0.8 with {col}:\")\n",
    "        print(correlation[col][(correlation[col] > 0.8) & (correlation[col] < 1)].to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607a9d3e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a05ca44",
   "metadata": {},
   "source": [
    "### **Categorical Variable VS Categorical Variable**\n",
    "\n",
    "> To calculate the correlation between two categorical variables, we will use the **Cramer's V correlation**.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "#### **Cramer's V Correlation** <sup>[4]</sup>\n",
    "\n",
    "Cram√©r's V (Cram√©r, 1946) is measure is actually designed for the chi-square test for independence but can be adjusted for the goodness-of-fit test (Kelley & Preacher, 2012, p. 145; Mangiafico, 2016, p. 474) <sup>[5]</sup><sup>[6]</sup>. It gives an estimate of how well the data then fits the expected values, where 0 would indicate that they are exactly equal. If you use the equal distributed expected values (as we did in the example) the maximum value would be 1, otherwise it could actually also exceed 1.\n",
    "\n",
    "Its formula is:\n",
    "\n",
    "\\begin{equation*}\n",
    "V_{gof} = \\sqrt{\\frac{\\chi^2}{n \\times df}}\n",
    "\\end{equation*}\n",
    "\n",
    "Where $\\chi^2$ is the chi-square value of the chi-square test, $n$ the number of data points, and $df$ the degrees of freedom, which is the number of categories, minus one in for this.\n",
    "\n",
    "<br>\n",
    "\n",
    "Cohen shown that Cram√©r's V can be converted to Cohen's w using (Cohen, 1988, p. 223) <sup>[7]</sup>:\n",
    "\n",
    "$$w = V_{gof}\\times \\sqrt{df}$$\n",
    "\n",
    "We could then use Cohen's rule-of-thumb for the interpertation (Cohen, 1988, pp. 224-225) <sup>[7]</sup>:\n",
    "\n",
    "| Cohen w      | Interpretation |\n",
    "|--------------|----------------|\n",
    "| 0 < .10      | Negligible     |\n",
    "| 0.10 < 0.30  | Small          |\n",
    "| 0.30 < 0.50  | Medium         |\n",
    "| 0.50 or more | Large          |\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca625ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation Matrix of the all columns - Categorical Variables [Cramer's V Correlation]\n",
    "# Source: https://www.kaggle.com/code/chrisbss1/cramer-s-v-correlation-matrix\n",
    "\n",
    "# OHE encoding of the categorical variables for the calculation of the Cramer's V correlation\n",
    "df_ohe = ABCDEats.copy()\n",
    "ohe = OneHotEncoder(sparse_output=False, drop=\"first\")\n",
    "ohe_feat = ohe.fit_transform(df_ohe[list(set(non_metric_cols) - {'customer_age_group'})])\n",
    "ohe_feat_names = ohe.get_feature_names_out()\n",
    "\n",
    "# Get feature names and create a DataFrame \n",
    "# with the one-hot encoded categorical features (pass feature names)\n",
    "df_ohe = pd.DataFrame(ohe_feat, columns=ohe_feat_names, index=df_ohe.index)\n",
    "df_ohe = df_ohe[df_ohe.columns.sort_values()]\n",
    "df_ohe[ohe_feat_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "4d234ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the one-hot encoded categorical features into the original DataFrame ABCDEats\n",
    "ABCDEats = pd.concat([ABCDEats, df_ohe[ohe_feat_names]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad19000f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Cramer's V correlation matrix\n",
    "# Source: https://stackoverflow.com/questions/46498455/categorical-features-correlation/46498792#46498792\n",
    "import scipy.stats as ss\n",
    "\n",
    "def cramers_v(var1,var2):\n",
    "    \"\"\"\n",
    "    Calculate Cramers V statistic for categorial-categorial association.\n",
    "    uses correction from Bergsma and Wicher, Journal of the Korean Statistical Society 42 (2013): 323-328\n",
    "    \"\"\"\n",
    "    confusion_matrix = pd.crosstab(var1,var2).values\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    n = confusion_matrix.sum()\n",
    "    phi2 = chi2 / n\n",
    "    r, k = confusion_matrix.shape\n",
    "    phi2corr = max(0, phi2 - ((k-1)*(r-1))/(n-1))\n",
    "    rcorr = r - ((r-1)**2)/(n-1)\n",
    "    kcorr = k - ((k-1)**2)/(n-1)\n",
    "    return np.sqrt(phi2corr / min((kcorr-1), (rcorr-1)))\n",
    "\n",
    "# Building of the matrix\n",
    "rows= []\n",
    "\n",
    "# Append 'customer_age_group' to the DataFrame\n",
    "df_ohe['customer_age_group'] = ABCDEats['customer_age_group']\n",
    "\n",
    "# Sort the columns of the DataFrame\n",
    "df_ohe = df_ohe[df_ohe.columns.sort_values()]\n",
    "\n",
    "for var1 in tqdm(df_ohe.columns):\n",
    "  col = []\n",
    "  for var2 in df_ohe.columns:\n",
    "    cramers =cramers_v(df_ohe[var1], df_ohe[var2]) # Cramer's V Test\n",
    "    col.append(round(cramers,2))                   # Keeping of the rounded value of the Cramer's V\n",
    "  rows.append(col)\n",
    "\n",
    "cramers_results = np.array(rows)\n",
    "cramers_results_df = pd.DataFrame(cramers_results, columns = df_ohe.columns, index = df_ohe.columns)\n",
    "cramers_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3c290c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heatmap of the Cramer's V correlation matrix\n",
    "\n",
    "# Show only high or low values: values above |0.3| will appear annotated in the plot\n",
    "mask_annot = np.absolute(cramers_results_df.values) >= 0.3\n",
    "annot = np.where(mask_annot, cramers_results_df.values, np.full(cramers_results_df.shape,\"\"))\n",
    "\n",
    "# Create a mask to hide the upper triangle of the correlation matrix\n",
    "mask = np.zeros_like(cramers_results_df, dtype=np.bool_)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Plot the correlation matrix as a Heatmap\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "sns.heatmap(cramers_results_df,\n",
    "            cmap='Blues',\n",
    "            annot=annot,    # Show only VERY high or VERY low values\n",
    "            fmt='s',        # fmt='s' -> string format\n",
    "            # annot=True, \n",
    "            # fmt='.2f',\n",
    "            annot_kws={'fontsize':8},\n",
    "            cbar_kws={'shrink':0.8},\n",
    "            vmin=0, vmax=1, center=0.5,\n",
    "            linewidths=0.5, square=True, mask=mask)\n",
    "plt.title(\"Cramer's V Correlation Matrix of the Categorical Variables\\n\", fontsize=16, fontweight='bold')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('')\n",
    "plt.xticks(ticks=np.arange(len(cramers_results_df.columns)) + 0.5, # Center the ticks\n",
    "           labels=cramers_results_df.columns,\n",
    "           fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "fig.savefig('./Preprocessing_Outputs/Cramers_V_Correlation_Matrix_Categorical_Variables.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab40ee8723b0e94",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8090b763fb2a5202",
   "metadata": {},
   "source": [
    "#  **üïµÔ∏è‚Äç‚ôÇÔ∏è PCA (Principal Component Analysis)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637772b2",
   "metadata": {},
   "source": [
    "#### **Scaling Data** [StandardScaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "a10de134",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCDEats_standard = ABCDEats.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b45abf987f3cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-18T14:26:20.189388Z",
     "start_time": "2024-10-18T14:26:20.186427Z"
    }
   },
   "outputs": [],
   "source": [
    "ss_scaler = StandardScaler()\n",
    "ss_scaled_feat = ss_scaler.fit_transform(ABCDEats[metric_cols])\n",
    "ss_scaled_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7164520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See what the fit method is doing (notice the trailing underscore):\n",
    "print(\"Parameters fitted:\\n\")\n",
    "pd.DataFrame([ss_scaler.mean_, np.sqrt(ss_scaler.var_)], columns=metric_cols, index=['mean','std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a5a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCDEats_standard[metric_cols] = ss_scaled_feat\n",
    "ABCDEats_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f402553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking mean and variance of standardized variables\n",
    "ABCDEats_standard[metric_cols].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "84ef3e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = ABCDEats_standard.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2f50b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NAs\n",
    "ABCDEats_standard.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30f5488",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa6f5b89",
   "metadata": {},
   "source": [
    "#### **PCA** [`CUI`]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28a9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cuisines_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8428ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce dimensionality of data\n",
    "pca_cui = PCA()\n",
    "cuisines_cols_excluded_cols = ['CUI_Total_Amount_Spent', 'CUI_Most_Spent_Cuisine', 'CUI_Total_Food_Types', 'CUI_Avg_Amount_Spent']\n",
    "cuisines_cols_selected_cols = [col for col in cuisines_cols if col not in cuisines_cols_excluded_cols]\n",
    "pca_feat_cui = pca_cui.fit_transform(df_pca[cuisines_cols_selected_cols])\n",
    "pca_feat_cui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12595c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCA output as table\n",
    "\n",
    "# Get the eigenvalues (explained variance)\n",
    "explained_variance = pca_cui.explained_variance_ \n",
    "\n",
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca_cui.explained_variance_ratio_ \n",
    "\n",
    "# get the cumulative explained variance ratio \n",
    "# Hint: use np.cumsum()\n",
    "cumulative_explained_variance_ratio = np.cumsum(pca_cui.explained_variance_ratio_)          \n",
    "\n",
    "# Combine into a dataframe\n",
    "pca_results = pd.DataFrame(\n",
    "    {\n",
    "        \"Eigenvalue\": explained_variance,\n",
    "        \"Difference\": np.insert(np.diff(explained_variance), 0, 0),\n",
    "        \"Proportion\": explained_variance_ratio,\n",
    "        \"Cumulative\": cumulative_explained_variance_ratio\n",
    "    },\n",
    "        index=range(1, pca_cui.n_components_ + 1)\n",
    ")\n",
    "\n",
    "def _eigenvalue_highlighter(row):\n",
    "    \"\"\"\n",
    "    Highlight row with eigenvalue greater than 1\n",
    "    \"\"\"\n",
    "    if row['Eigenvalue'] >=1:\n",
    "        return ['background-color: #f5fcce'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "# Apply styling to the DataFrame\n",
    "pca_results.style.format({\n",
    "    'Eigenvalue': '{:.2f}',\n",
    "    'Difference': '{:.2f}',\n",
    "    'Proportion': '{:.2f}',\n",
    "    'Cumulative': '{:.2f}'\n",
    "}).apply(_eigenvalue_highlighter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a5db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# draw plots\n",
    "\n",
    "ax1.plot(explained_variance, # PLOT THE EIGENVALUES (EXPLAINED VARIANCE)\n",
    "         marker=\".\", markersize=12)\n",
    "\n",
    "ax2.plot(explained_variance_ratio, # PLOT THE EXPLAINED VARIANCE RATIO\n",
    "         marker=\".\", markersize=12, label=\"Proportion\")\n",
    "\n",
    "ax2.plot(cumulative_explained_variance_ratio, # PLOT THE CUMULATIVE EXPLAINED VARIANCE RATIO\n",
    "         marker=\".\", markersize=12, linestyle=\"--\", label=\"Cumulative\")\n",
    "\n",
    "# customizations\n",
    "ax2.legend()\n",
    "ax1.set_title(\"Scree Plot [CUI]\\n\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_title(\"Variance Explained [CUI]\\n\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_ylabel(\"Eigenvalue\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Proportion\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Components\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Components\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_xticks(range(0, pca_cui.n_components_, 2))\n",
    "ax1.set_xticklabels(range(1, pca_cui.n_components_ + 1, 2))\n",
    "ax2.set_xticks(range(0, pca_cui.n_components_, 2))\n",
    "ax2.set_xticklabels(range(1, pca_cui.n_components_ + 1, 2))\n",
    "\n",
    "# Add Lines and Annotations\n",
    "ax1.axhline(1, color=\"red\", linestyle=\"--\")\n",
    "ax1.annotate(\"Eigenvalue = 1\", (4, 1), (4.2, 1.2), arrowprops={\"arrowstyle\": \"->\", \"color\": \"red\"}, fontsize=12, color=\"red\", fontweight=\"bold\")\n",
    "ax1.axvline(4, color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "ax2.axhline(0.8, color=\"blue\", linestyle=\"--\")\n",
    "ax2.annotate(\"80% Explained Variance\", (11, 0.8), (9, 0.6), arrowprops={\"arrowstyle\": \"->\", \"color\": \"blue\"}, fontsize=12, color=\"blue\", fontweight=\"bold\")\n",
    "ax2.axvline(11, color=\"lightblue\", linestyle=\"--\")\n",
    "\n",
    "sns.despine(right=True, top=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0818a4ba",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size:16px;\">\n",
    "\n",
    "> **1st Rule of Thumb:** Keep $80\\%$ of the total variance $\\rightarrow$ **`n_components=12`** **[Variance Explained by each PC]**\n",
    "\n",
    "> **2nd Rule of Thumb:** Keep the components with eigenvalues greater than 1 $\\rightarrow$ $PC \\;var \\ge 1$ $\\rightarrow$ **`n_components = 4`**\n",
    "\n",
    "> **3rd Rule of Thumb:** Keep the components based on the **Scree Plot** $\\rightarrow$ **`n_components = 4`**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97da1639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA again with the number of principal components you want to retain\n",
    "pca_cui_final = PCA(n_components=7)\n",
    "pca_feat_cui_final = pca_cui_final.fit_transform(df_pca[cuisines_cols_selected_cols])\n",
    "pca_feat_names_cui_final = [f\"PC{i}\" for i in range(pca_cui_final.n_components_)]\n",
    "\n",
    "# remember index=df_pca.index\n",
    "pca_df_cui = pd.DataFrame(pca_feat_cui_final, index=df_pca.index, columns=pca_feat_names_cui_final)  \n",
    "pca_df_cui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "10629dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings\n",
    "loadings = pd.concat([df_pca, pca_df_cui], axis=1)[cuisines_cols_selected_cols + pca_feat_names_cui_final].corr().loc[cuisines_cols_selected_cols, pca_feat_names_cui_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90784c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlight loadings greater than 0.4 or less than -0.4\n",
    "def _color_red_or_green(val):\n",
    "    if val < -0.40:\n",
    "        color = 'background-color: #ffbdbd'\n",
    "    elif val > 0.40:\n",
    "        color = 'background-color: #b3ffcc'\n",
    "    else:\n",
    "        color = ''\n",
    "    return color\n",
    "\n",
    "# Apply the style to the loadings\n",
    "loadings.style.applymap(_color_red_or_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "e14b4633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the PCs\n",
    "# PC0: CUI_Italian + CUI_OTHER + NOT_Asian + NOT_Street Food / Snacks\n",
    "# PC1: CUI_American + CUI_Cafe + CUI_Japanese\n",
    "# PC2: CUI_Chicken Dishes + CUI_Chinese + CUI_Noodle Dishes\n",
    "# PC3: CUI_Healthy + NOT_American\n",
    "# PC4: CUI_Indian \n",
    "# PC5: CUI_Japanese + NOT_Beverages\n",
    "# PC6: CUI_Beverages + CUI_Thai\n",
    "\n",
    "# Append the PCA features to the dataset\n",
    "ABCDEats_standard = pd.concat([ABCDEats_standard, pca_df_cui], axis=1)\n",
    " \n",
    "# Rename the columns\n",
    "pca_feat_names = ['CUI_NOTAsian_Italian_OTHER_NOTSnack_PC', 'CUI_American_Cafe_Japanese_PC', 'CUI_Chicken_Chinese_Noodle_PC', \n",
    "                  'CUI_Healthy_NOTAmerican_PC', 'CUI_Indian_PC', 'CUI_Japanese_NOTBeverages_PC', 'CUI_Beverages_Thai_PC']\n",
    "ABCDEats_standard.rename(columns=dict(zip(pca_df_cui.columns, pca_feat_names)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7a8865",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(pca_cui_final.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84bfbb97",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64693d8f",
   "metadata": {},
   "source": [
    "#### **PCA** [`DOW`] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb1e02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de6b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce dimensionality of data\n",
    "pca_dow = PCA()\n",
    "pca_feat_dow = pca_dow.fit_transform(df_pca[weekdays_cols])\n",
    "pca_feat_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a7ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCA output as table\n",
    "\n",
    "# Get the eigenvalues (explained variance)\n",
    "explained_variance = pca_dow.explained_variance_ \n",
    "\n",
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca_dow.explained_variance_ratio_ \n",
    "\n",
    "# get the cumulative explained variance ratio \n",
    "# Hint: use np.cumsum()\n",
    "cumulative_explained_variance_ratio = np.cumsum(pca_dow.explained_variance_ratio_)          \n",
    "\n",
    "# Combine into a dataframe\n",
    "pca_results = pd.DataFrame(\n",
    "    {\n",
    "        \"Eigenvalue\": explained_variance,\n",
    "        \"Difference\": np.insert(np.diff(explained_variance), 0, 0),\n",
    "        \"Proportion\": explained_variance_ratio,\n",
    "        \"Cumulative\": cumulative_explained_variance_ratio\n",
    "    },\n",
    "        index=range(1, pca_dow.n_components_ + 1)\n",
    ")\n",
    "\n",
    "def _eigenvalue_highlighter(row):\n",
    "    \"\"\"\n",
    "    Highlight row with eigenvalue greater than 1\n",
    "    \"\"\"\n",
    "    if row['Eigenvalue'] > 0.99:\n",
    "        return ['background-color: #f5fcce'] * len(row)\n",
    "    return [''] * len(row)\n",
    "\n",
    "# Apply styling to the DataFrame\n",
    "pca_results.style.format({\n",
    "    'Eigenvalue': '{:.2f}',\n",
    "    'Difference': '{:.2f}',\n",
    "    'Proportion': '{:.2f}',\n",
    "    'Cumulative': '{:.2f}'\n",
    "}).apply(_eigenvalue_highlighter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd49576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# draw plots\n",
    "\n",
    "ax1.plot(explained_variance, # PLOT THE EIGENVALUES (EXPLAINED VARIANCE)\n",
    "         marker=\".\", markersize=12)\n",
    "\n",
    "ax2.plot(explained_variance_ratio, # PLOT THE EXPLAINED VARIANCE RATIO\n",
    "         marker=\".\", markersize=12, label=\"Proportion\")\n",
    "\n",
    "ax2.plot(cumulative_explained_variance_ratio, # PLOT THE CUMULATIVE EXPLAINED VARIANCE RATIO\n",
    "         marker=\".\", markersize=12, linestyle=\"--\", label=\"Cumulative\")\n",
    "\n",
    "# customizations\n",
    "ax2.legend()\n",
    "ax1.set_title(\"Scree Plot [DOW]\\n\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_title(\"Variance Explained [DOW]\\n\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_ylabel(\"Eigenvalue\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Proportion\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Components\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Components\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_xticks(range(0, pca_dow.n_components_, 2))\n",
    "ax1.set_xticklabels(range(1, pca_dow.n_components_ + 1, 2))\n",
    "ax2.set_xticks(range(0, pca_dow.n_components_, 2))\n",
    "ax2.set_xticklabels(range(1, pca_dow.n_components_ + 1, 2))\n",
    "\n",
    "# Add Lines and Annotations\n",
    "ax1.axhline(1, color=\"red\", linestyle=\"--\")\n",
    "ax1.annotate(\"Eigenvalue >= 1\", (0, 1), (4, 1.03), fontsize=12, color=\"red\", fontweight=\"bold\")\n",
    "ax1.axvline(1, color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "ax2.axhline(0.8, color=\"blue\", linestyle=\"--\")\n",
    "ax2.annotate(\"80% Explained Variance\", (4, 0.8), (4, 0.6), arrowprops={\"arrowstyle\": \"->\", \"color\": \"blue\"}, fontsize=12, color=\"blue\", fontweight=\"bold\")\n",
    "ax2.axvline(4, color=\"lightblue\", linestyle=\"--\")\n",
    "\n",
    "sns.despine(right=True, top=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e49e78",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size:16px;\">\n",
    "\n",
    "> **1st Rule of Thumb:** Keep $80\\%$ of the total variance $\\rightarrow$ **`n_components=5`** **[Variance Explained by each PC]**\n",
    "\n",
    "> **2nd Rule of Thumb:** Keep the components with eigenvalues greater than 1 $\\rightarrow$ $PC \\;var \\ge 1$ $\\rightarrow$ **`n_components = 1`**\n",
    "\n",
    "> **3rd Rule of Thumb:** Keep the components based on the **Scree Plot** $\\rightarrow$ **`n_components = 2`**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7411b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA again with the number of principal components you want to retain\n",
    "pca_dow_final = PCA(n_components=3)\n",
    "pca_feat_dow_final = pca_dow_final.fit_transform(df_pca[weekdays_cols])\n",
    "pca_feat_names_dow_final = [f\"PC{i}\" for i in range(pca_dow_final.n_components_)]\n",
    "\n",
    "# remember index=df_pca.index\n",
    "pca_df_dow = pd.DataFrame(pca_feat_dow_final, index=df_pca.index, columns=pca_feat_names_dow_final)  \n",
    "pca_df_dow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "088c5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings\n",
    "loadings_dow = pd.concat([df_pca, pca_df_dow], axis=1)[weekdays_cols + pca_feat_names_dow_final].corr().loc[weekdays_cols, pca_feat_names_dow_final]\n",
    "\n",
    "# Rename index - days of the week (DOW_0 -> Sunday, DOW_1 -> Monday, ..., DOW_6 -> Saturday)\n",
    "loadings_dow.index = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abf1189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the style to the loadings\n",
    "loadings_dow.style.map(_color_red_or_green)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6085369",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\" style=\"font-size:36px;\">\n",
    "\n",
    "> N√ÉO FAZER !!!\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "88bf7e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to rename the variables DOW_0, DOW_1, ..., DOW_6 to the days of the week\n",
    "dow_names = dict(zip(weekdays_cols, ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "b5a9e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the variables DOW_0, DOW_1, ..., DOW_6 to the days of the week\n",
    "ABCDEats_standard.rename(columns=dow_names, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d946678",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d8bf9e9",
   "metadata": {},
   "source": [
    "#### **PCA** [`HR`] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c949e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hours_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fa9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce dimensionality of data\n",
    "pca_hr = PCA()\n",
    "pca_feat_hr = pca_hr.fit_transform(df_pca[hours_cols])\n",
    "pca_feat_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f4211c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get PCA output as table\n",
    "\n",
    "# Get the eigenvalues (explained variance)\n",
    "explained_variance = pca_hr.explained_variance_\n",
    "\n",
    "# Get the explained variance ratio\n",
    "explained_variance_ratio = pca_hr.explained_variance_ratio_\n",
    "\n",
    "# get the cumulative explained variance ratio\n",
    "# Hint: use np.cumsum()\n",
    "cumulative_explained_variance_ratio = np.cumsum(pca_hr.explained_variance_ratio_)\n",
    "\n",
    "# Combine into a dataframe\n",
    "pca_results = pd.DataFrame(\n",
    "    {\n",
    "        \"Eigenvalue\": explained_variance,\n",
    "        \"Difference\": np.insert(np.diff(explained_variance), 0, 0),\n",
    "        \"Proportion\": explained_variance_ratio,\n",
    "        \"Cumulative\": cumulative_explained_variance_ratio\n",
    "    },\n",
    "    index=range(1, pca_hr.n_components_ + 1)\n",
    ")\n",
    "\n",
    "# Apply styling to the DataFrame\n",
    "pca_results.style.format({\n",
    "    'Eigenvalue': '{:.2f}',\n",
    "    'Difference': '{:.2f}',\n",
    "    'Proportion': '{:.2f}',\n",
    "    'Cumulative': '{:.2f}'\n",
    "}).apply(_eigenvalue_highlighter, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc25f06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure and axes\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# draw plots\n",
    "\n",
    "ax1.plot(explained_variance, # PLOT THE EIGENVALUES (EXPLAINED VARIANCE)\n",
    "         marker=\".\", markersize=12)\n",
    "\n",
    "ax2.plot(explained_variance_ratio, # PLOT THE EXPLAINED VARIANCE RATIO\n",
    "            marker=\".\", markersize=12, label=\"Proportion\")\n",
    "\n",
    "ax2.plot(cumulative_explained_variance_ratio, # PLOT THE CUMULATIVE EXPLAINED VARIANCE RATIO\n",
    "            marker=\".\", markersize=12, linestyle=\"--\", label=\"Cumulative\")\n",
    "\n",
    "# customizations\n",
    "ax2.legend()\n",
    "ax1.set_title(\"Scree Plot [HR]\\n\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_title(\"Variance Explained [HR]\\n\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_ylabel(\"Eigenvalue\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_ylabel(\"Proportion\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Components\", fontsize=12, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Components\", fontsize=12, fontweight=\"bold\")\n",
    "ax1.set_xticks(range(0, pca_hr.n_components_, 2))\n",
    "ax1.set_xticklabels(range(1, pca_hr.n_components_ + 1, 2))\n",
    "ax2.set_xticks(range(0, pca_hr.n_components_, 2))\n",
    "ax2.set_xticklabels(range(1, pca_hr.n_components_ + 1, 2))\n",
    "\n",
    "# Add Lines and Annotations\n",
    "ax1.axhline(1, color=\"red\", linestyle=\"--\")\n",
    "ax1.annotate(\"Eigenvalue = 1\", (8, 1), (8.2, 1.2), arrowprops={\"arrowstyle\": \"->\", \"color\": \"red\"}, fontsize=12, color=\"red\", fontweight=\"bold\")\n",
    "\n",
    "# Represent Scree \n",
    "ax1.axvline(3, color=\"orange\", linestyle=\"--\")\n",
    "\n",
    "ax2.axhline(0.8, color=\"blue\", linestyle=\"--\")\n",
    "ax2.annotate(\"80% Explained Variance\", (16, 0.8), (16, 0.6), arrowprops={\"arrowstyle\": \"->\", \"color\": \"blue\"}, fontsize=12, color=\"blue\", fontweight=\"bold\")\n",
    "ax2.axvline(16, color=\"lightblue\", linestyle=\"--\")\n",
    "\n",
    "sns.despine(right=True, top=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357fea2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\" style=\"font-size:16px;\">\n",
    "\n",
    "> **1st Rule of Thumb:** Keep $80\\%$ of the total variance $\\rightarrow$ **`n_components=5`** **[Variance Explained by each PC]**\n",
    "\n",
    "> **2nd Rule of Thumb:** Keep the components with eigenvalues greater than 1 $\\rightarrow$ $PC \\;var \\ge 1$ $\\rightarrow$ **`n_components = 9`**\n",
    " \n",
    "> **3rd Rule of Thumb:** Keep the components based on the **Scree Plot** $\\rightarrow$ **`n_components = 4`**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41294805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA again with the number of principal components you want to retain\n",
    "pca_hr_final = PCA(n_components=4)\n",
    "pca_feat_hr_final = pca_hr_final.fit_transform(df_pca[hours_cols])\n",
    "pca_feat_names_hr_final = [f\"PC{i}\" for i in range(pca_hr_final.n_components_)]\n",
    "\n",
    "pca_df_hr = pd.DataFrame(pca_feat_hr_final, index=df_pca.index, columns=pca_feat_names_hr_final)\n",
    "pca_df_hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "79511146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loadings\n",
    "loadings_hr = pd.concat([df_pca, pca_df_hr], axis=1)[hours_cols + pca_feat_names_hr_final].corr().loc[hours_cols, pca_feat_names_hr_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed4fe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the style to the loadings\n",
    "loadings_hr.style.map(_color_red_or_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd818c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================== [EXTRA] ======================\n",
    "# Highlight the maximum absolute value in each row\n",
    "def highlight_max_abs(s):\n",
    "    is_max = s.abs() == s.abs().max()\n",
    "    return ['background-color: #ffeb99' if v else '' for v in is_max]\n",
    "\n",
    "# Apply the styles\n",
    "loadings.style.apply(highlight_max_abs, axis=1)\n",
    "\n",
    "# Highlight the maximum absolute value in each row\n",
    "loadings_hr.style.apply(highlight_max_abs, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523541b8",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\" style=\"font-size:36px;\">\n",
    "\n",
    "> Depois de fazer o PCA com 4, 5 e 6 componentes, o melhor √© com 4 componentes pq interpretabilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f645b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming the PCs\n",
    "# PC0 -> HR_11 - HR_14 | HR_17 - HR_20     [Lunch & Dinner]\n",
    "# PC1 -> HR_1 - HR_10                      [Late Night+ Breakfast]\n",
    "# PC2 -> HR_21 - HR_0                      [Evening]\n",
    "# PC3 -> HR_15 - HR_16                     [Afternoon Snack]\n",
    "\n",
    "# Append the PCA features to the dataset\n",
    "ABCDEats_standard = pd.concat([ABCDEats_standard, pca_df_hr], axis=1)\n",
    "\n",
    "# Rename the columns\n",
    "pca_feat_names = ['HR_Lunch_Dinner_PC', 'HR_LateNight_Breakfast_PC', 'HR_Evening_PC', 'HR_AfternoonSnack_PC']\n",
    "ABCDEats_standard.rename(columns=dict(zip(pca_df_hr.columns, pca_feat_names)), inplace=True)\n",
    "\n",
    "sum(pca_hr_final.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ab7850",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "622ee49654b791e2",
   "metadata": {},
   "source": [
    "# **üíæ Save Data** \n",
    "\n",
    "<br>\n",
    "\n",
    "- To finish this notebook and proceed Cluster Analysis, we will save the data to a new file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420ae5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 'customer_id' as the index\n",
    "ABCDEats_standard.set_index('customer_id', inplace=True)\n",
    "ABCDEats_standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b28f518dc8015233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the preprocessed dataset\n",
    "ABCDEats_standard.to_parquet('data/DM2425_ABCDEats_preprocessed.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea3c3134",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
